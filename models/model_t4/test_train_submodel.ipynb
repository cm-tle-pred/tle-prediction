{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import normalize_data\n",
    "import random\n",
    "import train\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from dataset import Dataset, to_device\n",
    "from model import NNBig\n",
    "from time import time\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "pd.set_option('display.max_columns', 999)\n",
    "pd.set_option('display.precision', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ref_X_y(df):\n",
    "    ref_cols = [c for c in df.columns if c.startswith('__')]\n",
    "    X_cols = [c for c in df.columns if c.startswith('X_')]\n",
    "    y_cols = [c for c in df.columns if c.startswith('y_')]\n",
    "    return (df[ref_cols], df[X_cols], df[y_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = {} # loads raw data and stores as a dict cache\n",
    "\n",
    "def dataset_key(dataset='', validation=False):\n",
    "    return dataset+('test' if validation else 'train')\n",
    "\n",
    "\n",
    "def load_data(raw, dataset='', validation=False):\n",
    "    '''\n",
    "    Return dataframe matching data set and validation. Dictionary input will be updated.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    raw : dict\n",
    "        dictionary which caches the dataframes and will be updated accordingly\n",
    "\n",
    "    dataset : str\n",
    "        which dataset to use? valid input includes: empty str for full set, sample_, and secret_\n",
    "\n",
    "    validation : bool\n",
    "        load validation set? if true then use _test, otherwise use _train.  Note secret_ doesn't have _train\n",
    "    '''\n",
    "    key = dataset+('test' if validation else 'train')\n",
    "    if key not in raw:\n",
    "        print(f\"Loading data to cache for: {key}\")\n",
    "        raw[key] = pd.read_pickle(f'{os.environ[\"GP_HIST_PATH\"]}/../t4_data/{key}.pkl')\n",
    "    return raw[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "configurations = {\n",
    "    'dataset' : '', # '', 'sample_', 'secret_'\n",
    "    'model_identifier' : \"GOLD_FULL\",\n",
    "    'model_path' : f\"{os.environ['GP_HIST_PATH']}/../t4_models\",\n",
    "    'device' : 'cpu',\n",
    "    'random_seed' : 0,\n",
    "    'max_epochs' : 50000,\n",
    "    'do_validate' : True,\n",
    "    'model_definition' : [ # this is only used to control the base and feature sequential layers\n",
    "        ('layer', 1000), ('relu', None),\n",
    "        ('layer', 500), ('relu', None),\n",
    "    ],\n",
    "    'feature_head_out' : 100,\n",
    "    'train_params' : {\n",
    "        'batch_size': 200000,\n",
    "        'shuffle': True,\n",
    "        'num_workers': 3,\n",
    "        'pin_memory': True,\n",
    "    },\n",
    "    'test_params' : {\n",
    "        'batch_size': 200000,\n",
    "        'num_workers': 3,\n",
    "        'pin_memory': True,\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 7s, sys: 39.4 s, total: 1min 46s\n",
      "Wall time: 1min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "train_df = normalize_data.normalize_all_columns(load_data(raw_data,dataset=configurations['dataset'],validation=False))\n",
    "test_df = normalize_data.normalize_all_columns(load_data(raw_data,dataset=configurations['dataset'],validation=True))\n",
    "\n",
    "train_df = train_df.dropna()\n",
    "test_df = test_df.dropna()\n",
    "# train_df = train_df.sample(100000, random_state=42)\n",
    "# test_df = test_df.sample(10000, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_train, X_train, y_train = get_ref_X_y(train_df)\n",
    "ref_test, X_test, y_test = get_ref_X_y(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_cols = ['y_INCLINATION', 'y_ECCENTRICITY', 'y_MEAN_MOTION', 'y_RA_OF_ASC_NODE_REG', 'y_RA_OF_ASC_NODE', 'y_ARG_OF_PERICENTER_REG', 'y_ARG_OF_PERICENTER', 'y_BSTAR', 'y_REV_MA_REG', 'y_MEAN_ANOMALY']\n",
    "y_cols = ['y_INCLINATION', 'y_ECCENTRICITY', 'y_MEAN_MOTION', 'y_RA_OF_ASC_NODE_REG', 'y_ARG_OF_PERICENTER_REG', 'y_REV_MA_REG']\n",
    "y_cols = ['y_RA_OF_ASC_NODE_REG']\n",
    "y_train = y_train[y_cols]\n",
    "y_test = y_test[y_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading existing model\n"
     ]
    }
   ],
   "source": [
    "path = configurations.get('model_path', None)\n",
    "torch.manual_seed(configurations.get('random_seed',0))\n",
    "device = configurations.get('device','cpu')\n",
    "pyt_device = torch.device(device)\n",
    "\n",
    "training_set = Dataset(X_train, y_train)\n",
    "training_generator = torch.utils.data.DataLoader(training_set, **configurations['train_params'])\n",
    "testing_set = Dataset(X_test, y_test)\n",
    "testing_generator = torch.utils.data.DataLoader(testing_set, **configurations['test_params'])\n",
    "\n",
    "full_net, loss_func, optimizer, mean_losses, next_epoch, = train.load_model_with_config(configurations, training_set, False)\n",
    "\n",
    "net = full_net.raan_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdamW (\n",
      "Parameter Group 0\n",
      "    amsgrad: True\n",
      "    betas: (0.9, 0.999)\n",
      "    eps: 1e-08\n",
      "    lr: 0.0001\n",
      "    weight_decay: 0.001\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(net.parameters(), lr=0.00001, weight_decay=0.0001, amsgrad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0dc94eca912c4cf082e93863432a6c04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/47185 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/498 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fd69fb051f0>\n",
      "\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/data1/home/ttcchen/anaconda3/envs/siads-orbital/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1324, in __del__\n",
      "  File \"/data1/home/ttcchen/anaconda3/envs/siads-orbital/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1324, in __del__\n",
      "        self._shutdown_workers()self._shutdown_workers()\n",
      "\n",
      "  File \"/data1/home/ttcchen/anaconda3/envs/siads-orbital/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1316, in _shutdown_workers\n",
      "  File \"/data1/home/ttcchen/anaconda3/envs/siads-orbital/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1316, in _shutdown_workers\n",
      "    if w.is_alive():    \n",
      "  File \"/data1/home/ttcchen/anaconda3/envs/siads-orbital/lib/python3.8/multiprocessing/process.py\", line 160, in is_alive\n",
      "if w.is_alive():    \n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "  File \"/data1/home/ttcchen/anaconda3/envs/siads-orbital/lib/python3.8/multiprocessing/process.py\", line 160, in is_alive\n",
      "AssertionError    : assert self._parent_pid == os.getpid(), 'can only test a child process'can only test a child process\n",
      "\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fd69fb051f0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/data1/home/ttcchen/anaconda3/envs/siads-orbital/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1324, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/data1/home/ttcchen/anaconda3/envs/siads-orbital/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1316, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/data1/home/ttcchen/anaconda3/envs/siads-orbital/lib/python3.8/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fd69fb051f0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/data1/home/ttcchen/anaconda3/envs/siads-orbital/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1324, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/data1/home/ttcchen/anaconda3/envs/siads-orbital/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1316, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/data1/home/ttcchen/anaconda3/envs/siads-orbital/lib/python3.8/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fd69fb051f0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/data1/home/ttcchen/anaconda3/envs/siads-orbital/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1324, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/data1/home/ttcchen/anaconda3/envs/siads-orbital/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1316, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/data1/home/ttcchen/anaconda3/envs/siads-orbital/lib/python3.8/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fd69fb051f0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/data1/home/ttcchen/anaconda3/envs/siads-orbital/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1324, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/data1/home/ttcchen/anaconda3/envs/siads-orbital/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1316, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/data1/home/ttcchen/anaconda3/envs/siads-orbital/lib/python3.8/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/498 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fd69fb051f0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/data1/home/ttcchen/anaconda3/envs/siads-orbital/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1324, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/data1/home/ttcchen/anaconda3/envs/siads-orbital/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1316, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/data1/home/ttcchen/anaconda3/envs/siads-orbital/lib/python3.8/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fd69fb051f0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/data1/home/ttcchen/anaconda3/envs/siads-orbital/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1324, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/data1/home/ttcchen/anaconda3/envs/siads-orbital/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1316, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/data1/home/ttcchen/anaconda3/envs/siads-orbital/lib/python3.8/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fd69fb051f0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/data1/home/ttcchen/anaconda3/envs/siads-orbital/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1324, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/data1/home/ttcchen/anaconda3/envs/siads-orbital/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1316, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/data1/home/ttcchen/anaconda3/envs/siads-orbital/lib/python3.8/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fd69fb051f0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/data1/home/ttcchen/anaconda3/envs/siads-orbital/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1324, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/data1/home/ttcchen/anaconda3/envs/siads-orbital/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1316, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/data1/home/ttcchen/anaconda3/envs/siads-orbital/lib/python3.8/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fd69fb051f0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/data1/home/ttcchen/anaconda3/envs/siads-orbital/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1324, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/data1/home/ttcchen/anaconda3/envs/siads-orbital/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1316, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/data1/home/ttcchen/anaconda3/envs/siads-orbital/lib/python3.8/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fd69fb051f0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/data1/home/ttcchen/anaconda3/envs/siads-orbital/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1324, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/data1/home/ttcchen/anaconda3/envs/siads-orbital/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1316, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/data1/home/ttcchen/anaconda3/envs/siads-orbital/lib/python3.8/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/498 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fd69fb051f0><function _MultiProcessingDataLoaderIter.__del__ at 0x7fd69fb051f0>\n",
      "\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/data1/home/ttcchen/anaconda3/envs/siads-orbital/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1324, in __del__\n",
      "  File \"/data1/home/ttcchen/anaconda3/envs/siads-orbital/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1324, in __del__\n",
      "        self._shutdown_workers()self._shutdown_workers()\n",
      "\n",
      "  File \"/data1/home/ttcchen/anaconda3/envs/siads-orbital/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1316, in _shutdown_workers\n",
      "  File \"/data1/home/ttcchen/anaconda3/envs/siads-orbital/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1316, in _shutdown_workers\n",
      "        if w.is_alive():if w.is_alive():\n",
      "  File \"/data1/home/ttcchen/anaconda3/envs/siads-orbital/lib/python3.8/multiprocessing/process.py\", line 160, in is_alive\n",
      "\n",
      "      File \"/data1/home/ttcchen/anaconda3/envs/siads-orbital/lib/python3.8/multiprocessing/process.py\", line 160, in is_alive\n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "\n",
      "AssertionError: AssertionError: can only test a child processcan only test a child process\n",
      "\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fd69fb051f0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/data1/home/ttcchen/anaconda3/envs/siads-orbital/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1324, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/data1/home/ttcchen/anaconda3/envs/siads-orbital/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1316, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/data1/home/ttcchen/anaconda3/envs/siads-orbital/lib/python3.8/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fd69fb051f0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/data1/home/ttcchen/anaconda3/envs/siads-orbital/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1324, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/data1/home/ttcchen/anaconda3/envs/siads-orbital/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1316, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/data1/home/ttcchen/anaconda3/envs/siads-orbital/lib/python3.8/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fd69fb051f0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/data1/home/ttcchen/anaconda3/envs/siads-orbital/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1324, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/data1/home/ttcchen/anaconda3/envs/siads-orbital/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1316, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/data1/home/ttcchen/anaconda3/envs/siads-orbital/lib/python3.8/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fd69fb051f0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/data1/home/ttcchen/anaconda3/envs/siads-orbital/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1324, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/data1/home/ttcchen/anaconda3/envs/siads-orbital/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1316, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/data1/home/ttcchen/anaconda3/envs/siads-orbital/lib/python3.8/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc44ff93ab18452380c3bf2bfd7dbf04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/498 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fd69fb051f0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/data1/home/ttcchen/anaconda3/envs/siads-orbital/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1324, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/data1/home/ttcchen/anaconda3/envs/siads-orbital/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1316, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/data1/home/ttcchen/anaconda3/envs/siads-orbital/lib/python3.8/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fd69fb051f0>\n",
      "Exception ignored in: Traceback (most recent call last):\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7fd69fb051f0>  File \"/data1/home/ttcchen/anaconda3/envs/siads-orbital/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1324, in __del__\n",
      "    \n",
      "self._shutdown_workers()Traceback (most recent call last):\n",
      "\n",
      "  File \"/data1/home/ttcchen/anaconda3/envs/siads-orbital/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1324, in __del__\n",
      "      File \"/data1/home/ttcchen/anaconda3/envs/siads-orbital/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1316, in _shutdown_workers\n",
      "self._shutdown_workers()\n",
      "      File \"/data1/home/ttcchen/anaconda3/envs/siads-orbital/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1316, in _shutdown_workers\n",
      "if w.is_alive():    \n",
      "if w.is_alive():  File \"/data1/home/ttcchen/anaconda3/envs/siads-orbital/lib/python3.8/multiprocessing/process.py\", line 160, in is_alive\n",
      "\n",
      "      File \"/data1/home/ttcchen/anaconda3/envs/siads-orbital/lib/python3.8/multiprocessing/process.py\", line 160, in is_alive\n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'    \n",
      "AssertionErrorassert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      ": AssertionErrorcan only test a child process\n",
      ": can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fd69fb051f0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/data1/home/ttcchen/anaconda3/envs/siads-orbital/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1324, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/data1/home/ttcchen/anaconda3/envs/siads-orbital/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1316, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/data1/home/ttcchen/anaconda3/envs/siads-orbital/lib/python3.8/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fd69fb051f0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/data1/home/ttcchen/anaconda3/envs/siads-orbital/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1324, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/data1/home/ttcchen/anaconda3/envs/siads-orbital/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1316, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/data1/home/ttcchen/anaconda3/envs/siads-orbital/lib/python3.8/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fd69fb051f0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/data1/home/ttcchen/anaconda3/envs/siads-orbital/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1324, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/data1/home/ttcchen/anaconda3/envs/siads-orbital/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1316, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/data1/home/ttcchen/anaconda3/envs/siads-orbital/lib/python3.8/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7fd69fb051f0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/data1/home/ttcchen/anaconda3/envs/siads-orbital/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1324, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/data1/home/ttcchen/anaconda3/envs/siads-orbital/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1297, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/data1/home/ttcchen/anaconda3/envs/siads-orbital/lib/python3.8/multiprocessing/process.py\", line 149, in join\n",
      "    res = self._popen.wait(timeout)\n",
      "  File \"/data1/home/ttcchen/anaconda3/envs/siads-orbital/lib/python3.8/multiprocessing/popen_fork.py\", line 44, in wait\n",
      "    if not wait([self.sentinel], timeout):\n",
      "  File \"/data1/home/ttcchen/anaconda3/envs/siads-orbital/lib/python3.8/multiprocessing/connection.py\", line 931, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/data1/home/ttcchen/anaconda3/envs/siads-orbital/lib/python3.8/selectors.py\", line 415, in select\n",
      "    fd_event_list = self._selector.poll(timeout)\n",
      "KeyboardInterrupt: \n",
      "Exception ignored in: <function WeakValueDictionary.__init__.<locals>.remove at 0x7fd6af24a820>\n",
      "Traceback (most recent call last):\n",
      "  File \"/data1/home/ttcchen/anaconda3/envs/siads-orbital/lib/python3.8/weakref.py\", line 103, in remove\n",
      "    def remove(wr, selfref=ref(self), _atomic_removal=_remove_dead_weakref):\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-3688d3a1898b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m             \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m     \u001b[0;31m# input x and predict based on x\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m     \u001b[0;31m# must be (1. nn output, 2. target)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m         \u001b[0;31m# backpropagation, compute gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/siads-orbital/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mistorage/mads/ttcchen/tle-prediction/models/model_t4/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0mhead_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m         target_out = self.model(\n\u001b[1;32m     63\u001b[0m             \u001b[0mhead_out\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/siads-orbital/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mistorage/mads/ttcchen/tle-prediction/models/model_t4/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/siads-orbital/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/siads-orbital/lib/python3.8/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/siads-orbital/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/siads-orbital/lib/python3.8/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/siads-orbital/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1751\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1753\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1754\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1755\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "to_device(net, pyt_device)\n",
    "net.train()\n",
    "#     print(net)\n",
    "\n",
    "if next_epoch == configurations['max_epochs']:\n",
    "    print(\"Model finished training. To retrain set force_train = True \")\n",
    "    net.eval()\n",
    "else:\n",
    "    epbar = tqdm(range(next_epoch, configurations['max_epochs']))\n",
    "    for epoch in epbar:\n",
    "        epbar.set_description(f\"Epoch {epoch+1}\")\n",
    "\n",
    "        running_eloss = 0\n",
    "        running_vloss = 0\n",
    "\n",
    "        ipbar = tqdm(training_generator, leave=False)\n",
    "        ipbar.set_description(f\"Training\")\n",
    "\n",
    "        for i, (x, y) in enumerate(ipbar):\n",
    "            x = to_device(x, pyt_device)\n",
    "            y = to_device(y, pyt_device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            prediction = net(x)     # input x and predict based on x\n",
    "            loss = loss_func(prediction, y)     # must be (1. nn output, 2. target)\n",
    "            loss.backward()         # backpropagation, compute gradients\n",
    "            optimizer.step()        # apply gradients\n",
    "            running_eloss += loss.item()\n",
    "\n",
    "        net.eval()\n",
    "        mean_vlosses = 0\n",
    "#         if configurations['do_validate']:\n",
    "#             with torch.set_grad_enabled(False):\n",
    "#                 vpbar = tqdm(testing_generator, leave=False)\n",
    "#                 vpbar.set_description(\"Validating\")\n",
    "#                 for i, (x, y) in enumerate(vpbar):\n",
    "#                     x = to_device(x, pyt_device)\n",
    "#                     y = to_device(y, pyt_device)\n",
    "#                     prediction = net(x)\n",
    "#                     loss = loss_func(prediction, y)\n",
    "#                     running_vloss += loss.item()\n",
    "#             mean_vlosses = running_vloss / len(testing_generator)\n",
    "\n",
    "        mean_elosses = running_eloss / len(training_generator)\n",
    "        mean_losses.append((mean_elosses, mean_vlosses))\n",
    "        \n",
    "        full_net.raan_model = net # save the full_net back\n",
    "        \n",
    "        train.save_model_with_config(configurations, net=full_net, loss_func=loss_func, optimizer=optimizer,\n",
    "                               mean_losses=mean_losses, next_epoch=epoch+1,\n",
    "                              )\n",
    "        net.train()\n",
    "\n",
    "        epbar.set_postfix({'train_loss':f\"{mean_elosses:.9f}\", 'val_loss':f\"{mean_vlosses:.9f}\"})\n",
    "    net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.save_model_with_config(configurations, net=full_net, loss_func=loss_func, optimizer=optimizer,\n",
    "                               mean_losses=mean_losses, next_epoch=epoch+1,\n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, _, _, mean_losses, _ = train.load_model_with_config(configurations)\n",
    "\n",
    "tl, vl = zip(*mean_losses)\n",
    "\n",
    "fig,ax = plt.subplots()\n",
    "ax.plot(tl, label=\"Training Loss\")\n",
    "ax.plot(vl, label=\"Validation Loss\")\n",
    "\n",
    "fig.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_idx = random.sample(list(X_test.index), 10000)\n",
    "\n",
    "X_sample = X_test.loc[sample_idx]\n",
    "y_sample = y_test.loc[sample_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train_pred = train.predict(trained_model, X_train, y_train, device=\"cpu\") # get predictions for each train\n",
    "# y_train_pred_df = pd.DataFrame(y_train_pred, columns=y_train.columns)  # put results into a dataframe\n",
    "y_sample_pred = train.predict(trained_model, X_sample, y_sample, device=\"cpu\") # get predictions for each train\n",
    "y_sample_pred_df = pd.DataFrame(y_sample_pred, columns=y_sample.columns)  # put results into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'    Test set MAE (L1) loss: {mean_absolute_error(y_sample, y_sample_pred_df)}')\n",
    "print(f'    Test set MSE (L2) loss: {mean_squared_error(y_sample, y_sample_pred_df)}')\n",
    "\n",
    "# random.seed(342798)\n",
    "sample = random.sample(list(y_sample_pred_df.index), 10)\n",
    "# sample = [0,1]\n",
    "\n",
    "print(\"Test - Ground Truth (normalized):\")\n",
    "display(y_sample)\n",
    "print(\"Test - Prediction (normalized):\")\n",
    "display(y_sample_pred_df)\n",
    "print(\"Ground Truth Diffs from X_:\")\n",
    "display(y_sample - X_sample[['X_INCLINATION_1','X_ECCENTRICITY_1','X_MEAN_MOTION_1']].values)\n",
    "print(\"Pred Diffs from X_:\")\n",
    "display(y_sample_pred_df - X_sample[['X_INCLINATION_1','X_ECCENTRICITY_1','X_MEAN_MOTION_1']].values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f'    Train set MAE (L1) loss: {mean_absolute_error(y_train, y_train_pred_df)}')\n",
    "# print(f'    Train set MSE (L2) loss: {mean_squared_error(y_train, y_train_pred_df)}')\n",
    "\n",
    "# random.seed(0)\n",
    "# sample = random.sample(list(y_train_pred_df.index), 10)\n",
    "\n",
    "# print(\"Train - Ground Truth (normalized):\")\n",
    "# display(y_train.loc[sample])\n",
    "# # print(\"Train - Ground Truth (non-normalized):\")\n",
    "# # display(normalize_data.normalize_all_columns(y_train.iloc[:,3:].loc[sample].copy(), reverse=True))  # see ground truths\n",
    "# print(\"Train - Prediction (normalized):\")\n",
    "# display(y_train_pred_df.loc[sample])\n",
    "# # print(\"Train - Prediction (non-normalized):\")\n",
    "# # display(normalize_data.normalize_all_columns(y_train_pred_df.loc[sample].copy(), reverse=True))  # See predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# errors = y_train.loc[sample].iloc[:,3:] - y_train_pred_df.loc[sample]\n",
    "\n",
    "# display(errors)\n",
    "\n",
    "# display(errors.std())\n",
    "\n",
    "# display(y_train.loc[sample].iloc[:,3:])\n",
    "# display(y_train_pred_df.loc[sample])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def row_to_compare(X, y, y_pred, row):\n",
    "#     epoch = X.iloc[row].EPOCH_y\n",
    "#     X0 = clean_data.normalize_all_columns(X_train.iloc[row].copy(), reverse=True)\n",
    "#     y0 = clean_data.normalize_all_columns(y_train.iloc[row].copy(), reverse=True)\n",
    "#     y1 = clean_data.normalize_all_columns(y_train_pred_df.iloc[row].copy(), reverse=True)\n",
    "\n",
    "#     # Ground truth\n",
    "#     y0_xyz = clean_data.get_satellite_xyz(bst=0.0001,\n",
    "#                                           ecc=y0.ECCENTRICITY,\n",
    "#                                           aop=y0.ARG_OF_PERICENTER,\n",
    "#                                           inc=y0.INCLINATION,\n",
    "#                                           mea=y0.MEAN_ANOMALY,\n",
    "#                                           mem=y0.MEAN_MOTION,\n",
    "#                                           raa=y0.RA_OF_ASC_NODE,\n",
    "#                                           epoch=epoch,)\n",
    "#     # Prediction\n",
    "#     y1_xyz = clean_data.get_satellite_xyz(bst=0.0001,\n",
    "#                                           ecc=y1.ECCENTRICITY,\n",
    "#                                           aop=y1.ARG_OF_PERICENTER,\n",
    "#                                           inc=y1.INCLINATION,\n",
    "#                                           mea=y1.MEAN_ANOMALY,\n",
    "#                                           mem=y1.MEAN_MOTION,\n",
    "#                                           raa=y1.RA_OF_ASC_NODE,\n",
    "#                                           epoch=epoch,)\n",
    "#     # Propigation\n",
    "#     y2_xyz = clean_data.get_satellite_xyz(bst=X0.BSTAR,\n",
    "#                                           ecc=X0.ECCENTRICITY,\n",
    "#                                           aop=X0.ARG_OF_PERICENTER,\n",
    "#                                           inc=X0.INCLINATION,\n",
    "#                                           mea=X0.MEAN_ANOMALY,\n",
    "#                                           mem=X0.MEAN_MOTION,\n",
    "#                                           raa=X0.RA_OF_ASC_NODE,\n",
    "#                                           epoch=epoch,)\n",
    "#     print(f'Ground Truth: {y0_xyz}')\n",
    "#     print(f'Predicted: {y1_xyz}')\n",
    "#     print(f'Propigation: {y2_xyz}')\n",
    "    \n",
    "#     print (f'Prediction Error: {sum((y1_xyz-y0_xyz)**2)**0.5} km')\n",
    "#     print (f'Propigation Error: {sum((y2_xyz-y0_xyz)**2)**0.5} km')\n",
    "    \n",
    "\n",
    "# for row in range(2):\n",
    "#     print (f'Row {row}:')\n",
    "#     row_to_compare(X_train, y_train, y_train_pred_df, row)\n",
    "#     print('')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
