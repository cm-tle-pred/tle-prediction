{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13b8ab5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from math import ceil\n",
    "from statistics import mean\n",
    "\n",
    "import re\n",
    "#################################\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as Data\n",
    "\n",
    "#################################\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append('../model_0')\n",
    "from model import NNModelEx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b6717359",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if data needs to be re-generated, rerun this cell\n",
    "# this are globals\n",
    "all_data = None\n",
    "sampled_data = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36149e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_device(data, device):\n",
    "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
    "    if isinstance(data, (list,tuple)):\n",
    "        return [to_device(x, device) for x in data]\n",
    "    return data.to(device, non_blocking=True)\n",
    "\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "    'Characterizes a dataset for PyTorch'\n",
    "    def __init__(self, inp, tgt, device='cpu'):\n",
    "        'Initialization'\n",
    "        self.inp = to_device(torch.from_numpy(inp).float(), device)\n",
    "        self.tgt = to_device(torch.from_numpy(tgt).float(), device)\n",
    "        self.num_X = inp.shape[1]\n",
    "        self.num_y = tgt.shape[1]\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the total number of samples'\n",
    "        return len(self.tgt)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generates one sample of data'\n",
    "        return self.inp[index], self.tgt[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "150d911c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ref_X_y(df):\n",
    "    ref_cols = [c for c in df.columns if c.startswith('__')]\n",
    "    X_cols = [c for c in df.columns if c.startswith('X_')]\n",
    "    y_cols = [c for c in df.columns if c.startswith('y_')]\n",
    "    return (df[ref_cols], df[X_cols], df[y_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d5e5265",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_with_config(config):\n",
    "    # kinda lazy here so using global to avoid reloading the datasets\n",
    "    global sampled_data, all_data\n",
    "    if config['use_sampled'] == True:\n",
    "        if sampled_data == None:\n",
    "            print(\"Loading sampled data\")\n",
    "            sampled_data = load_and_scale_data(prefix = \"sample_\")\n",
    "        return sampled_data\n",
    "    else:\n",
    "        if all_data == None:\n",
    "            print(\"Loading all data\")\n",
    "            all_data = load_and_scale_data()\n",
    "        return all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b52fc93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_scale_data(ignore_cols=[], prefix=\"\"):\n",
    "    train_df = pd.read_pickle(f\"{os.environ['GP_HIST_PATH']}/../3_min/{prefix}train.pkl\")\n",
    "    test_df = pd.read_pickle(f\"{os.environ['GP_HIST_PATH']}/../3_min/{prefix}test.pkl\")\n",
    "    \n",
    "    # move columns from X or y to ref\n",
    "    ignore_dict = {x:re.sub('^.', '_', x, 1) for x in ignore_cols}\n",
    "    train_df = train_df.rename(columns=ignore_dict)\n",
    "    test_df = test_df.rename(columns=ignore_dict)\n",
    "    \n",
    "    ref_train, X_train, y_train = get_ref_X_y(train_df)\n",
    "    ref_test, X_test, y_test = get_ref_X_y(test_df)\n",
    "\n",
    "    X_min_max_scaler = MinMaxScaler()\n",
    "    y_min_max_scaler = MinMaxScaler()\n",
    "\n",
    "    X_train = X_min_max_scaler.fit_transform(X_train)\n",
    "    y_train = y_min_max_scaler.fit_transform(y_train)\n",
    "    X_test = X_min_max_scaler.fit_transform(X_test)\n",
    "    y_test = y_min_max_scaler.fit_transform(y_test)\n",
    "    \n",
    "    return train_df, test_df, X_min_max_scaler, y_min_max_scaler, ref_train, X_train, y_train, ref_test, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77ca9557",
   "metadata": {},
   "outputs": [],
   "source": [
    "configurations = {\n",
    "    'model_identifier' : \"sample_model_pipe_test_1\",\n",
    "    'use_sampled' : True,\n",
    "    'random_seed' : 0,\n",
    "    'lr' : 1e-5,\n",
    "    'weight_decay' : 1e-6,\n",
    "    'max_epochs' : 50,\n",
    "    'do_validate' : True,\n",
    "    'model_definition' : {\n",
    "        'drop__0': 0.6,\n",
    "        'layer_1': 100, 'relu__1': True, 'drop__1': 0.5,\n",
    "        'layer_2': 100, 'relu__2': True, 'drop__2': 0.5,\n",
    "        'layer_3': 100, 'relu__3': True, 'drop__3': 0.7,\n",
    "        'layer_4': 50,  'relu__4': True, 'drop__4': 0.4,\n",
    "        'layer_5': 50,  'relu__5': True, 'drop__5': 0.4,\n",
    "    },\n",
    "    'train_params' : {\n",
    "        'batch_size': 1000,\n",
    "        'shuffle': True,\n",
    "        'num_workers': 3,\n",
    "    },\n",
    "    'test_params' : {\n",
    "        'batch_size': 20000,\n",
    "        'num_workers': 3,\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9ec05fe3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading sampled data\n",
      "Creating Dataset and Dataloader\n",
      "NNModelEx(\n",
      "  (net): Sequential(\n",
      "    (0): Dropout(p=0.6, inplace=False)\n",
      "    (1): Linear(in_features=16, out_features=100, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): Dropout(p=0.5, inplace=False)\n",
      "    (4): Linear(in_features=100, out_features=100, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Dropout(p=0.5, inplace=False)\n",
      "    (7): Linear(in_features=100, out_features=100, bias=True)\n",
      "    (8): ReLU()\n",
      "    (9): Dropout(p=0.7, inplace=False)\n",
      "    (10): Linear(in_features=100, out_features=50, bias=True)\n",
      "    (11): ReLU()\n",
      "    (12): Dropout(p=0.4, inplace=False)\n",
      "    (13): Linear(in_features=50, out_features=50, bias=True)\n",
      "    (14): ReLU()\n",
      "    (15): Dropout(p=0.4, inplace=False)\n",
      "    (16): Linear(in_features=50, out_features=6, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a08725f10baf44139fa8d7d9e5e2acec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5081073112b2429fb2edb937924b8109",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2820 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-605310ba8c86>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mipbar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m     \u001b[0;31m# input x and predict based on x\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m     \u001b[0;31m# must be (1. nn output, 2. target)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m         \u001b[0;31m# backpropagation, compute gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/siads-orbital/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mistorage/mads/ttcchen/tle-prediction/models/model_0/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/siads-orbital/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/siads-orbital/lib/python3.8/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/siads-orbital/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/siads-orbital/lib/python3.8/site-packages/torch/nn/modules/dropout.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/siads-orbital/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mdropout\u001b[0;34m(input, p, training, inplace)\u001b[0m\n\u001b[1;32m   1074\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0.0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1075\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"dropout probability has to be between 0 and 1, \"\u001b[0m \u001b[0;34m\"but got {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1076\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1077\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1078\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_df, test_df, X_min_max_scaler, y_min_max_scaler, \\\n",
    " ref_train, X_train, y_train, ref_test, X_test, y_test = load_with_config(configurations)\n",
    "\n",
    "print(\"Creating Dataset and Dataloader\")\n",
    "training_set = Dataset(X_train, y_train)\n",
    "training_generator = torch.utils.data.DataLoader(training_set, **configurations['train_params'])\n",
    "testing_set = Dataset(X_test, y_test)\n",
    "testing_generator = torch.utils.data.DataLoader(testing_set, **configurations['test_params'])\n",
    "\n",
    "torch.manual_seed(configurations['random_seed'])\n",
    "\n",
    "net = NNModelEx(inputSize=training_set.num_X, outputSize=training_set.num_y, **configurations['model_definition'])\n",
    "print(net)  # net architecture\n",
    "\n",
    "loss_func = torch.nn.MSELoss()  # this is for regression mean squared loss\n",
    "losses = []\n",
    "\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=configurations['lr'], weight_decay=configurations['weight_decay'])\n",
    "\n",
    "# train the network\n",
    "epbar = tqdm(range(configurations['max_epochs']))\n",
    "for epoch in epbar:\n",
    "    epbar.set_description(f\"Epoch {epoch+1}\")\n",
    "\n",
    "    elosses = []\n",
    "    vlosses = []\n",
    "\n",
    "    ipbar = tqdm(training_generator, leave=False)\n",
    "    ipbar.set_description(f\"Training\")\n",
    "    \n",
    "    for i, (x, y) in enumerate(ipbar):\n",
    "        optimizer.zero_grad()\n",
    "        prediction = net(x)     # input x and predict based on x\n",
    "        loss = loss_func(prediction, y)     # must be (1. nn output, 2. target)\n",
    "        loss.backward()         # backpropagation, compute gradients\n",
    "        optimizer.step()        # apply gradients\n",
    "        elosses.append(loss.data.numpy().item())\n",
    "        ipbar.set_postfix({'loss': loss.data.numpy()})\n",
    "\n",
    "    mean_vlosses = 0\n",
    "    if configurations['do_validate']:\n",
    "        with torch.set_grad_enabled(False):\n",
    "            vpbar = tqdm(testing_generator, leave=False)\n",
    "            vpbar.set_description(\"Validating\")\n",
    "            for i, (x, y) in enumerate(vpbar):\n",
    "                prediction = net(x)\n",
    "                loss = loss_func(prediction, y)\n",
    "                vlosses.append(loss.data.numpy().item())\n",
    "                vpbar.set_postfix({'loss': loss.data.numpy()})\n",
    "        mean_vlosses = mean(vlosses)\n",
    "            \n",
    "    mean_elosses = mean(elosses)\n",
    "    losses.append((mean_elosses, mean_vlosses))\n",
    "    \n",
    "    epbar.set_postfix({'train_loss':f\"{mean_elosses:.9f}\", 'val_loss':f\"{mean_vlosses:.9f}\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5f2631",
   "metadata": {},
   "outputs": [],
   "source": [
    "tl, vl = zip(*losses)\n",
    "\n",
    "fig,ax = plt.subplots()\n",
    "ax.plot(tl, label=\"Training Loss\")\n",
    "ax.plot(vl, label=\"Validation Loss\")\n",
    "\n",
    "fig.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f353e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net,f\"{configurations['model_identifier']}.pt\")\n",
    "print(f\"Saved model as \\\"{configurations['model_identifier']}.pt\\\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
