{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from datetime import datetime\n",
    "from sgp4.api import Satrec, SatrecArray, WGS72"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def __jday_convert(x):\n",
    "    '''\n",
    "    Algorithm from python-sgp4:\n",
    "\n",
    "    from sgp4.functions import jday\n",
    "    jday(x.year, x.month, x.day, x.hour, x.minute, x.second + x.microsecond * 1e-6)\n",
    "    '''\n",
    "    jd = (367.0 * x.year\n",
    "         - 7 * (x.year + ((x.month + 9) // 12.0)) * 0.25 // 1.0\n",
    "           + 275 * x.month / 9.0 // 1.0\n",
    "           + x.day\n",
    "         + 1721013.5)\n",
    "    fr = (x.second + (x.microsecond * 1e-6) + x.minute * 60.0 + x.hour * 3600.0) / 86400.0;\n",
    "    return jd, fr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cyclic_repr(s,v):\n",
    "    cos = np.cos(np.deg2rad(s * (360/v)))\n",
    "    sin = np.sin(np.deg2rad(s * (360/v)))\n",
    "    return cos,sin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_satrec_erv(bst, ecc, aop, inc, mea, mem, raa, mmdot=0, mmddot=0, norad=0, epoch=None):\n",
    "    '''\n",
    "    Get cartesian coordinates of a satellite based on TLE parameters\n",
    "\n",
    "     Parameters\n",
    "     ----------\n",
    "     bst : float : B-star\n",
    "     ecc : float : eccentricity (in degrees)\n",
    "     aop : float : argument of perigee (in degrees)\n",
    "     inc : float : inclination (in degrees)\n",
    "     mea : float : mean anomaly (in degrees)\n",
    "     mem : float : mean motion (in degrees per minute)\n",
    "     raa : float : right ascension of ascending node (in degrees)\n",
    "     mmdot : float : NOT USED - ballistic coefficient\n",
    "     mmddot : float : NOT USED - mean motion 2nd derivative\n",
    "     norad : int : NOT USED - NORAD ID\n",
    "     epoch : Timestamp : moment in time to get position\n",
    "\n",
    "     Returns\n",
    "     -------\n",
    "     list\n",
    "         [e, rx, ry, rz, vx, vy, yz] error, position xyz, velocity xyz.  error = 0 is good\n",
    "    '''\n",
    "    try:\n",
    "        r = datetime.strptime('12/31/1949 00:00:00', '%m/%d/%Y %H:%M:%S')\n",
    "        epoch_days = (epoch-r)/np.timedelta64(1, 'D')\n",
    "        s = Satrec()\n",
    "        s.sgp4init(\n",
    "             WGS72,           # gravity model\n",
    "             'i',             # 'a' = old AFSPC mode, 'i' = improved mode\n",
    "             norad,               # satnum: Satellite number\n",
    "             epoch_days,       # epoch: days since 1949 December 31 00:00 UT\n",
    "             bst,      # bstar: drag coefficient (/earth radii)\n",
    "             mmdot,   # ndot (NOT USED): ballistic coefficient (revs/day)\n",
    "             mmddot,             # nddot (NOT USED): mean motion 2nd derivative (revs/day^3)\n",
    "             ecc,       # ecco: eccentricity\n",
    "             aop*np.pi/180, # argpo: argument of perigee (radians)\n",
    "             inc*np.pi/180, # inclo: inclination (radians)\n",
    "             mea*np.pi/180, # mo: mean anomaly (radians)\n",
    "             mem*np.pi/(4*180), # no_kozai: mean motion (radians/minute)\n",
    "             raa*np.pi/180, # nodeo: right ascension of ascending node (radians)\n",
    "        )\n",
    "        e,r,v = s.sgp4(*__jday_convert(epoch))\n",
    "        return pd.Series([e, *r, *v])\n",
    "    except:\n",
    "        return pd.Series([999, 0,0,0,0,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_feature_values(df):\n",
    "    name = df.name\n",
    "    df = df.sort_values(\"EPOCH\")\n",
    "    \n",
    "    \n",
    "    # we're skipping this part for model t1 since we aren't predicting TLEs\n",
    "#     # convert ARG_OF_PERICENTER, RA_OF_ASC_NODE, and MEAN_ANOMALY to non-cyclic version\n",
    "#     df[\"ARG_OF_PERICENTER_ADJUSTED\"] = np.cumsum(np.around(df.ARG_OF_PERICENTER.diff().fillna(0) / -360))*360 + df.ARG_OF_PERICENTER\n",
    "#     df[\"RA_OF_ASC_NODE_ADJUSTED\"] = np.cumsum(np.around(df.RA_OF_ASC_NODE.diff().fillna(0) / -360))*360 + df.RA_OF_ASC_NODE\n",
    "    \n",
    "#     # this is because for REV_AT_EPOCH = 100,000, it's recorded as 10,000 instead of 0\n",
    "#     # this doesn't handle the case for multiple ground stations reporting though, if the previous is different....\n",
    "#     # would it be better to just remove this as an outlier just to be safe?\n",
    "#     # 90k +- 20 max offset based on MEAN_MOTION maximum from earlier steps\n",
    "#     df.loc[(df.REV_AT_EPOCH==10000) & df.REV_AT_EPOCH.diff().between(-90020,-89980),'REV_AT_EPOCH'] = 0\n",
    "\n",
    "#     # combine REV_AT_EPOCH and MEAN_ANOMALY for a non-cyclic representation\n",
    "#     adjusted_rev = df.REV_AT_EPOCH + np.cumsum(np.around(df.REV_AT_EPOCH.diff().fillna(0) / -100000)) * 100000\n",
    "#     df[\"REV_MEAN_ANOMALY_COMBINED\"] = adjusted_rev * 360 + df.MEAN_ANOMALY\n",
    "    \n",
    "#     # this is to handle the REV_AT_EPOCH problem inconsistency problem\n",
    "#     # otherwise the REV_MEAN_ANOMALY_COMBINED difference may be incorrect\n",
    "#     # bfill because we may start at non-zero due to previous data removal bit\n",
    "#     a = np.round((adjusted_rev.diff().fillna(method='bfill')/2000)).fillna(0)\n",
    "#     df[\"SUBGROUP\"] = np.cumsum(a).astype(int)\n",
    "\n",
    "    # keeping this to keep the rest of the code unchanged\n",
    "    df[\"SUBGROUP\"] = 0\n",
    "    \n",
    "    doycos, doysin = cyclic_repr(df.EPOCH.dt.dayofyear, 366)\n",
    "    df[\"DAY_OF_YEAR_COS\"] = doycos\n",
    "    df[\"DAY_OF_YEAR_SIN\"] = doysin\n",
    "    \n",
    "    synodic = df.EPOCH.astype(int) % 2551442976000000\n",
    "    sidereal = df.EPOCH.astype(int) % 2360591510400000\n",
    "    \n",
    "    syn_m_cos, syn_m_sin = cyclic_repr(synodic, 2551442976000000)\n",
    "    df[\"SYNODIC_MONTH_COS\"] = syn_m_cos\n",
    "    df[\"SYNODIC_MONTH_SIN\"] = syn_m_sin\n",
    "\n",
    "    sr_m_cos, sr_m_sin = cyclic_repr(synodic, 2360591510400000)\n",
    "    df[\"SIDEREAL_MONTH_COS\"] = sr_m_cos\n",
    "    df[\"SIDEREAL_MONTH_SIN\"] = sr_m_sin\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input is 1 groupby of satellite\n",
    "def generate_X_y(df):\n",
    "    idx = df.name\n",
    "\n",
    "    df = df.reset_index().drop_duplicates(subset=['EPOCH']).sort_values(\"EPOCH\")\n",
    "    dfs = []\n",
    "    for i in range(1,11):\n",
    "        dfi = pd.concat([df,df.shift(-i).add_suffix(\"_b\")], axis=1).dropna()\n",
    "        dfs.append(dfi)\n",
    "    ddf = pd.concat(dfs)\n",
    "\n",
    "    # Reference variables only, DO NOT USE TO TRAIN\n",
    "    df = ddf[['NORAD_CAT_ID','GP_ID','GP_ID_b','EPOCH','EPOCH_b']]\n",
    "    df.columns = ['__NORAD_CAT_ID','__GP_ID_1','__GP_ID_2','__EPOCH_1','__EPOCH_2']\n",
    "    df['__GP_ID_2'] = df['__GP_ID_2'].astype(int)\n",
    "    \n",
    "    # Ignore these columns completely\n",
    "#     'MONTH', 'DAY', # month and day should be well-represented as day_of_year\n",
    "#     'REV_AT_EPOCH' # this one doesn't matter if we are predicting cartesian\n",
    "    \n",
    "    # X\n",
    "    x_cols = ['MEAN_MOTION_DOT', 'BSTAR', 'INCLINATION', 'RA_OF_ASC_NODE', 'ECCENTRICITY', 'ARG_OF_PERICENTER',\n",
    "              'MEAN_ANOMALY', 'MEAN_MOTION',\n",
    "              'YEAR', 'DAY_OF_YEAR_COS', 'DAY_OF_YEAR_SIN',\n",
    "              'SYNODIC_MONTH_COS', 'SYNODIC_MONTH_SIN', 'SIDEREAL_MONTH_COS', 'SIDEREAL_MONTH_SIN',\n",
    "              'SUNSPOTS_1D', 'SUNSPOTS_3D', 'SUNSPOTS_7D',\n",
    "              'AIR_MONTH_AVG_TEMP','WATER_MONTH_AVG_TEMP',\n",
    "              'SAT_RX', 'SAT_RY', 'SAT_RZ', 'SAT_VX', 'SAT_VY', 'SAT_VZ',\n",
    "             ]\n",
    "    \n",
    "    df[['X_EPOCH_JD', 'X_EPOCH_FR']] = ddf.EPOCH.apply(__jday_convert).to_list()\n",
    "    df['X_delta_EPOCH'] = (ddf.EPOCH_b - ddf.EPOCH).astype(int) / 86400000000000 # in days\n",
    "    df[['X_'+x for x in x_cols]] = ddf[x_cols]\n",
    "\n",
    "    # y\n",
    "    y_cols = ['SAT_RX', 'SAT_RY', 'SAT_RZ', 'SAT_VX', 'SAT_VY', 'SAT_VZ']\n",
    "    df[['y_'+y for y in y_cols]] = ddf[y_cols]\n",
    "    \n",
    "    # not sure if this day limiting thing makes sense....\n",
    "    df = df[(df['X_delta_EPOCH'] < 5) & (df['X_delta_EPOCH'] > 0.25)]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing data for: test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37e0a8c4aa4041009d40f6382e61d0e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2702 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7aeeb3c6c88c48a1ba0c7283ac97283f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2702 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing data for: train\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aeee763974f4418fa349456d7479c4ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12288 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bb909e4f4f24a12a21cf83318460dda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12288 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing data for: secret_test\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9869d859ba16432c9019897374d42b37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2711 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6c4614df4bf4df887fefe18a6250725",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2711 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1h 33min 43s, sys: 5min 37s, total: 1h 39min 21s\n",
      "Wall time: 1h 46min 26s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Generate actual data\n",
    "\n",
    "input_files = [\n",
    "    \"test\",\n",
    "    \"train\",\n",
    "    \"secret_test\",\n",
    "]\n",
    "\n",
    "for f in input_files:\n",
    "    print(f\"Preparing data for: {f}\")\n",
    "    df = pd.read_pickle(f\"{os.environ['GP_HIST_PATH']}/../3_min/{f}.pkl\")\n",
    "    converted_df = df.groupby(by=\"NORAD_CAT_ID\", as_index=False).progress_apply(convert_feature_values)\n",
    "    sgp4_df = pd.read_pickle(f\"{os.environ['GP_HIST_PATH']}/../3_min/{f}_sgp4rv.pkl\")\n",
    "    converted_df = converted_df.merge(sgp4_df, left_index=True, right_index=True)\n",
    "    processed_df = converted_df.groupby([\"NORAD_CAT_ID\",\"SUBGROUP\"], as_index=False).progress_apply(generate_X_y)\n",
    "    processed_df.reset_index(drop=True, inplace=True)\n",
    "    processed_df.to_pickle(f\"{os.environ['GP_HIST_PATH']}/../t1_data/{f}.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89b0bdb798e54a32879150be6e47d03c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12288 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1a1b971e30c4e57b7a5ecf584b9cbaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/490 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb042f7615c74f23b1b39a4103b29a78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10529520\n",
      "991306\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "\n",
    "# # generate smaller set from training set to test\n",
    "\n",
    "train_df = pd.read_pickle(f\"{os.environ['GP_HIST_PATH']}/../3_min/train.pkl\")\n",
    "converted_df = train_df.groupby(by=\"NORAD_CAT_ID\", as_index=False).progress_apply(convert_feature_values)\n",
    "\n",
    "\n",
    "# narrow down using certain inclination range only\n",
    "# sample_df = converted_df[converted_df.INCLINATION.between(65,67)]\n",
    "sample_df = converted_df\n",
    "\n",
    "sgp4_df = pd.read_pickle(f\"{os.environ['GP_HIST_PATH']}/../3_min/train_sgp4rv.pkl\")\n",
    "\n",
    "sample_df = sample_df.merge(sgp4_df, left_index=True, right_index=True)\n",
    "\n",
    "# narrow down further with random norad IDs\n",
    "train_ids = np.random.choice(sample_df.NORAD_CAT_ID.unique(), 500)\n",
    "test_ids = np.random.choice(list(set(sample_df.NORAD_CAT_ID.unique())-set(train_ids)),50)\n",
    "\n",
    "sample_train_df = sample_df[sample_df.NORAD_CAT_ID.isin(train_ids)]\n",
    "sample_test_df = sample_df[sample_df.NORAD_CAT_ID.isin(test_ids)]\n",
    "\n",
    "processed_sample_train_df = sample_train_df.groupby([\"NORAD_CAT_ID\",\"SUBGROUP\"], as_index=False).progress_apply(generate_X_y)\n",
    "processed_sample_train_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "processed_sample_test_df = sample_test_df.groupby([\"NORAD_CAT_ID\",\"SUBGROUP\"], as_index=False).progress_apply(generate_X_y)\n",
    "processed_sample_test_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# save samples\n",
    "processed_sample_train_df.to_pickle(f\"{os.environ['GP_HIST_PATH']}/../t1_data/sample_train.pkl\")\n",
    "processed_sample_test_df.to_pickle(f\"{os.environ['GP_HIST_PATH']}/../t1_data/sample_test.pkl\")\n",
    "\n",
    "print(len(processed_sample_train_df))\n",
    "print(len(processed_sample_test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
