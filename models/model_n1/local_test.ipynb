{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Truncating data...\n",
      ">>> Normalizing data...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import clean_data\n",
    "import random\n",
    "import train\n",
    "\n",
    "\n",
    "init_cols = ['BSTAR', 'INCLINATION', 'RA_OF_ASC_NODE', 'ECCENTRICITY', 'ARG_OF_PERICENTER', 'MEAN_ANOMALY',\n",
    "             'MEAN_MOTION', 'NORAD_CAT_ID', 'EPOCH', 'SUNSPOTS_1D', 'SUNSPOTS_3D', 'SUNSPOTS_7D',\n",
    "             'AIR_MONTH_AVG_TEMP', 'WATER_MONTH_AVG_TEMP',\n",
    "            ]\n",
    "\n",
    "def load_raw(name=None):\n",
    "    if not name:\n",
    "        train_df = pd.read_pickle(os.environ['GP_HIST_PATH'] + '/../3_min/train.pkl' ) # Time: 25.7s\n",
    "        test_df = pd.read_pickle(os.environ['GP_HIST_PATH'] + '/../3_min/test.pkl' ) # Time: 5\n",
    "        return {'train': train_df, 'test': test_df}\n",
    "    elif name == 'train':\n",
    "        return {name: pd.read_pickle(os.environ['GP_HIST_PATH'] + '/../3_min/train.pkl' )}\n",
    "    elif name == 'test':\n",
    "        return {name: pd.read_pickle(os.environ['GP_HIST_PATH'] + '/../3_min/test.pkl' )}\n",
    "train_df = load_raw('train')['train']\n",
    "\n",
    "print(f'>>> Truncating data...')\n",
    "train_df = train_df[init_cols].reset_index(drop=True)  # 4s\n",
    "\n",
    "print(f'>>> Normalizing data...')\n",
    "train_df = clean_data.normalize_all_columns(train_df) # 53.4s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_map = clean_data.load_index_map(name='train', path='data')[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(train_df.iloc[idx_map[:,0]].reset_index(drop=True),\n",
    "              train_df.iloc[idx_map[:,1]].reset_index(drop=True),\n",
    "              left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_idx=[0,1,2,3,4,5,6,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,39,40,41,42,43,44,45,46,47,48,49,8,33]\n",
    "y_idx=[26,27,28,29,30,31]\n",
    "X = df[list(df.columns[x_idx])]\n",
    "y = df[list(df.columns[y_idx])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>INCLINATION_y</th>\n",
       "      <th>RA_OF_ASC_NODE_y</th>\n",
       "      <th>ECCENTRICITY_y</th>\n",
       "      <th>ARG_OF_PERICENTER_y</th>\n",
       "      <th>MEAN_ANOMALY_y</th>\n",
       "      <th>MEAN_MOTION_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.345787</td>\n",
       "      <td>0.795126</td>\n",
       "      <td>0.282100</td>\n",
       "      <td>0.802900</td>\n",
       "      <td>0.176510</td>\n",
       "      <td>0.183388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.345651</td>\n",
       "      <td>0.601665</td>\n",
       "      <td>0.293362</td>\n",
       "      <td>0.188529</td>\n",
       "      <td>0.832906</td>\n",
       "      <td>0.185565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.345729</td>\n",
       "      <td>0.013095</td>\n",
       "      <td>0.314878</td>\n",
       "      <td>0.327711</td>\n",
       "      <td>0.695316</td>\n",
       "      <td>0.170153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.345819</td>\n",
       "      <td>0.095622</td>\n",
       "      <td>0.281552</td>\n",
       "      <td>0.775454</td>\n",
       "      <td>0.202845</td>\n",
       "      <td>0.183247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.345667</td>\n",
       "      <td>0.452867</td>\n",
       "      <td>0.305143</td>\n",
       "      <td>0.198696</td>\n",
       "      <td>0.824191</td>\n",
       "      <td>0.178082</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   INCLINATION_y  RA_OF_ASC_NODE_y  ECCENTRICITY_y  ARG_OF_PERICENTER_y  \\\n",
       "0       0.345787          0.795126        0.282100             0.802900   \n",
       "1       0.345651          0.601665        0.293362             0.188529   \n",
       "2       0.345729          0.013095        0.314878             0.327711   \n",
       "3       0.345819          0.095622        0.281552             0.775454   \n",
       "4       0.345667          0.452867        0.305143             0.198696   \n",
       "\n",
       "   MEAN_ANOMALY_y  MEAN_MOTION_y  \n",
       "0        0.176510       0.183388  \n",
       "1        0.832906       0.185565  \n",
       "2        0.695316       0.170153  \n",
       "3        0.202845       0.183247  \n",
       "4        0.824191       0.178082  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns = [col[:-2] if col[-2:] == '_x' else col for col in X.columns]\n",
    "y.columns = [col[:-2] if col[-2:] == '_y' else col for col in X.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = train_df.shape[1] #len(df.columns)\n",
    "combined = np.zeros([len(idx_map), w*2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined[:,:w] = train_df.iloc[idx_map[:,0]]\n",
    "combined[:,w:w*2] = train_df.iloc[idx_map[:,1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'key'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-e7e3b1677f87>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m df = pd.merge(train_df.iloc[idx_map[:,0]].reset_index(drop=True),\n\u001b[0m\u001b[0;32m      2\u001b[0m               \u001b[0mtrain_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx_map\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m               on='key')\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\cmtle\\lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36mmerge\u001b[1;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m     72\u001b[0m     \u001b[0mvalidate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m ) -> \"DataFrame\":\n\u001b[1;32m---> 74\u001b[1;33m     op = _MergeOperation(\n\u001b[0m\u001b[0;32m     75\u001b[0m         \u001b[0mleft\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m         \u001b[0mright\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\cmtle\\lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, left, right, how, on, left_on, right_on, axis, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m    666\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mright_join_keys\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    667\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin_names\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 668\u001b[1;33m         ) = self._get_merge_keys()\n\u001b[0m\u001b[0;32m    669\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    670\u001b[0m         \u001b[1;31m# validate the merge keys dtypes. We may need to coerce\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\cmtle\\lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36m_get_merge_keys\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1031\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_rkey\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1032\u001b[0m                         \u001b[1;32mif\u001b[0m \u001b[0mrk\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1033\u001b[1;33m                             \u001b[0mright_keys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mright\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_label_or_level_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1034\u001b[0m                         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1035\u001b[0m                             \u001b[1;31m# work-around for merge_asof(right_index=True)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\cmtle\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_get_label_or_level_values\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1682\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_level_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1683\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1684\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1685\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1686\u001b[0m         \u001b[1;31m# Check for duplicates\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'key'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_xy(df, idx_pairs,\n",
    "             x_idx=[0,1,2,3,4,5,6,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,39,40,41,42,43,44,45,46,47,48,49,8,33],\n",
    "             y_idx=[26,27,28,29,30,31],\n",
    "             debug=False):\n",
    "    '''\n",
    "    Builds an X (inputs e.g. X_train) and y (labels e.g. y_train) dataframes\n",
    "    by using the idx_pairs.  For example, idx_pairs of [[0,1]] will return a\n",
    "    single row which contains the values from df.iloc[0] and df.iloc[1] concat\n",
    "    and then split according to the x_idx and y_idx indexes into two df.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : Dataframe\n",
    "        Contains all the data to be trained on\n",
    "\n",
    "    idx_pairs : list\n",
    "        Contains list of lists where each list is a pair of row indexes for df\n",
    "\n",
    "    x_idx : list\n",
    "        Contains the column indexes that represent the X values.\n",
    "        Default: [0,1,2,3,4,5,6,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,\n",
    "                  39,40,41,42,43,44,45,46,47,48,49,\n",
    "                  8,33]\n",
    "\n",
    "    y_idx : list\n",
    "        Contains the column indexes that represent the y values\n",
    "        Default: [26,27,28,29,30,31]\n",
    "\n",
    "    debug : bool\n",
    "        Display the column indexes only.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    DataFrame\n",
    "        Contains the input values X\n",
    "\n",
    "    DataFrame\n",
    "        Contains the label values y\n",
    "    '''\n",
    "    \n",
    "    if debug:\n",
    "        display ({i:c for i,c in enumerate(df.columns)})\n",
    "        display ({i+len(df.columns):c for i,c in enumerate(df.columns)})\n",
    "        return None\n",
    "\n",
    "    columns = df.columns\n",
    "    X_columns,y_columns = [],[]\n",
    "    for i in x_idx:\n",
    "        c = columns[i%len(columns)]\n",
    "        if c in X_columns:\n",
    "            X_columns.append(c+'_y')\n",
    "        else:\n",
    "            X_columns.append(c)\n",
    "    for i in y_idx:\n",
    "        c = columns[i%len(columns)]\n",
    "        if c in y_columns:\n",
    "            y_columns.append(c+'_y')\n",
    "        else:\n",
    "            y_columns.append(c)\n",
    "\n",
    "    combined = np.concatenate([df.to_numpy()[idx_pairs[:,0]],\n",
    "                               df.to_numpy()[idx_pairs[:,1]]], axis=1)\n",
    "\n",
    "    X = pd.DataFrame(combined[:,x_idx], columns=X_columns)\n",
    "    y = pd.DataFrame(combined[:,y_idx], columns=y_columns).apply(pd.to_numeric)\n",
    "\n",
    "    num_cols = list(set(X.columns).difference({'EPOCH','EPOCH_y'}))\n",
    "    X[num_cols] = X[num_cols].apply(pd.to_numeric)\n",
    "\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def build(df):\n",
    "    print(f'>>> Truncating {name} data...')\n",
    "    df = df[init_cols].reset_index(drop=True)  # 4s\n",
    "\n",
    "    print(f'>>> Normalizing {name} data...')\n",
    "    df = clean_data.normalize_all_columns(df) # 53.4s\n",
    "\n",
    "    print(f'>>> Building {name} index map...')\n",
    "    try:\n",
    "        idx_map = clean_data.load_index_map(name=name, path='data')\n",
    "    except:\n",
    "        idx_map = clean_data.create_index_map(df, write=True, name=name, path='data') # 3min 29s\n",
    "\n",
    "#     print(f'>>> Building {name} inputs and labels')\n",
    "#     X,y = clean_data.build_xy(df, idx_map) # 59min 41s\n",
    "#     X = clean_data.normalize_epoch_diff(X, drop_epoch=False) # 19s"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
