{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0033299c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import clean_data\n",
    "\n",
    "model_cols = ['BSTAR', 'INCLINATION', 'RA_OF_ASC_NODE', 'ECCENTRICITY', 'ARG_OF_PERICENTER', 'MEAN_ANOMALY',\n",
    "              'MEAN_MOTION', 'epoch_jd', 'epoch_fr',\n",
    "              #'MEAN_MOTION_DOT', 'MEAN_MOTION_DDOT', \n",
    "             ]\n",
    "\n",
    "def clean_df(df):\n",
    "    df = clean_data.add_epoch_data(df)\n",
    "    df = clean_data.normalize_all_columns(df)\n",
    "    return df\n",
    "\n",
    "def clean_all(train_df, test_df):\n",
    "    train_df = clean_df(train_df)\n",
    "    test_df = clean_df(test_df)\n",
    "    return train_df,test_df\n",
    "\n",
    "def load_all():\n",
    "    train_df = pd.read_pickle('data/train.pkl' )\n",
    "    #test_df = pd.read_pickle('data/test.pkl' )\n",
    "    return train_df #, test_df\n",
    "\n",
    "train_df = load_all()\n",
    "#train_df,test_df = clean_all(train_df, test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d20b2be4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 21.05it/s]\n"
     ]
    }
   ],
   "source": [
    "train_df = train_df[train_df['NORAD_CAT_ID'] == 14631].reset_index(drop=True)\n",
    "train_df = clean_df(train_df)\n",
    "train_model_df = train_df[model_cols]\n",
    "idx_map = clean_data.create_index_map(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3841e03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "split = 0.8\n",
    "train_idx_map = idx_map[:int(len(idx_map)*split)]\n",
    "test_idx_map = idx_map[int(len(idx_map)*split):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db73d26e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NNModelEx(\n",
       "  (net): Sequential(\n",
       "    (0): Linear(in_features=11, out_features=300, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=300, out_features=300, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=300, out_features=200, bias=True)\n",
       "    (5): ReLU()\n",
       "    (6): Linear(in_features=200, out_features=7, bias=True)\n",
       "    (7): ReLU()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import train\n",
    "\n",
    "model = train.create_model(model_cols=model_cols,\n",
    "                           layer1=300, relu1=True, #drop1=0.5,\n",
    "                           layer2=300, relu2=True, #drop2=0.5,\n",
    "                           layer3=200, relu3=True, #drop3=0.5,\n",
    "                          )\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "594475e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Loading dataset\n",
      ">>> Beginning training!\n",
      "Epoch [1/500], Batch [8/8], Loss: 0.44924381375312805, Time: 2s\n",
      "Epoch [2/500], Batch [8/8], Loss: 0.45883363485336304, Time: 2s\n",
      "Epoch [3/500], Batch [8/8], Loss: 0.44349560141563416, Time: 2s\n",
      "Epoch [4/500], Batch [8/8], Loss: 0.43257537484169006, Time: 3s\n",
      "Epoch [5/500], Batch [8/8], Loss: 0.424635112285614, Time: 2s\n",
      "Epoch [6/500], Batch [8/8], Loss: 0.41281047463417053, Time: 2s\n",
      "Epoch [7/500], Batch [8/8], Loss: 0.40639063715934753, Time: 3s\n",
      "Epoch [8/500], Batch [8/8], Loss: 0.39052334427833557, Time: 3s\n",
      "Epoch [9/500], Batch [8/8], Loss: 0.3837663531303406, Time: 2s\n",
      "Epoch [10/500], Batch [8/8], Loss: 0.37476491928100586, Time: 3s\n",
      "Epoch [11/500], Batch [8/8], Loss: 0.3639633059501648, Time: 3s\n",
      "Epoch [12/500], Batch [8/8], Loss: 0.35396504402160645, Time: 3s\n",
      "Epoch [13/500], Batch [8/8], Loss: 0.3432087004184723, Time: 2s\n",
      "Epoch [14/500], Batch [8/8], Loss: 0.3446402847766876, Time: 2s\n",
      "Epoch [15/500], Batch [8/8], Loss: 0.3236660361289978, Time: 3s\n",
      "Epoch [16/500], Batch [8/8], Loss: 0.3247787654399872, Time: 3s\n",
      "Epoch [17/500], Batch [8/8], Loss: 0.3064976632595062, Time: 2s\n",
      "Epoch [18/500], Batch [8/8], Loss: 0.2918361723423004, Time: 3s\n",
      "Epoch [19/500], Batch [8/8], Loss: 0.27991652488708496, Time: 2s\n",
      "Epoch [20/500], Batch [8/8], Loss: 0.2875179350376129, Time: 2s\n",
      "Epoch [21/500], Batch [8/8], Loss: 0.26704153418540955, Time: 2s\n",
      "Epoch [22/500], Batch [8/8], Loss: 0.25407469272613525, Time: 2s\n",
      "Epoch [23/500], Batch [8/8], Loss: 0.24805277585983276, Time: 3s\n",
      "Epoch [24/500], Batch [8/8], Loss: 0.23752066493034363, Time: 2s\n",
      "Epoch [25/500], Batch [8/8], Loss: 0.23949836194515228, Time: 3s\n",
      "Epoch [26/500], Batch [8/8], Loss: 0.21732673048973083, Time: 3s\n",
      "Epoch [27/500], Batch [8/8], Loss: 0.20710311830043793, Time: 3s\n",
      "Epoch [28/500], Batch [8/8], Loss: 0.21512660384178162, Time: 3s\n",
      "Epoch [29/500], Batch [8/8], Loss: 0.19162507355213165, Time: 2s\n",
      "Epoch [30/500], Batch [8/8], Loss: 0.1819373369216919, Time: 2s\n",
      "Epoch [31/500], Batch [8/8], Loss: 0.17548635601997375, Time: 2s\n",
      "Epoch [32/500], Batch [8/8], Loss: 0.169279545545578, Time: 2s\n",
      "Epoch [33/500], Batch [8/8], Loss: 0.16115064918994904, Time: 3s\n",
      "Epoch [34/500], Batch [8/8], Loss: 0.15560807287693024, Time: 2s\n",
      "Epoch [35/500], Batch [8/8], Loss: 0.1477787047624588, Time: 2s\n",
      "Epoch [36/500], Batch [8/8], Loss: 0.14243857562541962, Time: 2s\n",
      "Epoch [37/500], Batch [8/8], Loss: 0.13401776552200317, Time: 2s\n",
      "Epoch [38/500], Batch [8/8], Loss: 0.12791332602500916, Time: 2s\n",
      "Epoch [39/500], Batch [8/8], Loss: 0.11956071853637695, Time: 2s\n",
      "Epoch [40/500], Batch [8/8], Loss: 0.11477544158697128, Time: 3s\n",
      "Epoch [41/500], Batch [8/8], Loss: 0.12199082225561142, Time: 3s\n",
      "Epoch [42/500], Batch [8/8], Loss: 0.10456985980272293, Time: 2s\n",
      "Epoch [43/500], Batch [8/8], Loss: 0.09911048412322998, Time: 2s\n",
      "Epoch [44/500], Batch [8/8], Loss: 0.0946798026561737, Time: 3s\n",
      "Epoch [45/500], Batch [8/8], Loss: 0.09074565023183823, Time: 2s\n",
      "Epoch [46/500], Batch [8/8], Loss: 0.0878019854426384, Time: 2s\n",
      "Epoch [47/500], Batch [8/8], Loss: 0.08566305786371231, Time: 2s\n",
      "Epoch [48/500], Batch [8/8], Loss: 0.08403285592794418, Time: 3s\n",
      "Epoch [49/500], Batch [8/8], Loss: 0.08200016617774963, Time: 2s\n",
      "Epoch [50/500], Batch [8/8], Loss: 0.07944610714912415, Time: 2s\n",
      "Epoch [51/500], Batch [8/8], Loss: 0.0782163068652153, Time: 2s\n",
      "Epoch [52/500], Batch [8/8], Loss: 0.0776878222823143, Time: 3s\n",
      "Epoch [53/500], Batch [8/8], Loss: 0.09191542118787766, Time: 3s\n",
      "Epoch [54/500], Batch [8/8], Loss: 0.07423880696296692, Time: 2s\n",
      "Epoch [55/500], Batch [8/8], Loss: 0.07559563219547272, Time: 3s\n",
      "Epoch [56/500], Batch [8/8], Loss: 0.08784336596727371, Time: 3s\n",
      "Epoch [57/500], Batch [8/8], Loss: 0.07395981252193451, Time: 2s\n",
      "Epoch [58/500], Batch [8/8], Loss: 0.08711469173431396, Time: 2s\n",
      "Epoch [59/500], Batch [8/8], Loss: 0.0721902921795845, Time: 3s\n",
      "Epoch [60/500], Batch [8/8], Loss: 0.0719970315694809, Time: 3s\n",
      "Epoch [61/500], Batch [8/8], Loss: 0.07328036427497864, Time: 2s\n",
      "Epoch [62/500], Batch [8/8], Loss: 0.07230178266763687, Time: 2s\n",
      "Epoch [63/500], Batch [8/8], Loss: 0.07213453203439713, Time: 3s\n",
      "Epoch [64/500], Batch [8/8], Loss: 0.07242167741060257, Time: 3s\n",
      "Epoch [65/500], Batch [8/8], Loss: 0.07290437817573547, Time: 2s\n",
      "Epoch [66/500], Batch [8/8], Loss: 0.07282306253910065, Time: 2s\n",
      "Epoch [67/500], Batch [8/8], Loss: 0.07142262160778046, Time: 2s\n",
      "Epoch [68/500], Batch [8/8], Loss: 0.07305438816547394, Time: 2s\n",
      "Epoch [69/500], Batch [8/8], Loss: 0.07230396568775177, Time: 2s\n",
      "Epoch [70/500], Batch [8/8], Loss: 0.07218614220619202, Time: 3s\n",
      "Epoch [71/500], Batch [8/8], Loss: 0.07329025864601135, Time: 2s\n",
      "Epoch [72/500], Batch [8/8], Loss: 0.07360570132732391, Time: 2s\n",
      "Epoch [73/500], Batch [8/8], Loss: 0.07263277471065521, Time: 3s\n",
      "Epoch [74/500], Batch [8/8], Loss: 0.07274578511714935, Time: 2s\n",
      "Epoch [75/500], Batch [8/8], Loss: 0.07335297763347626, Time: 2s\n",
      "Epoch [76/500], Batch [8/8], Loss: 0.07205365598201752, Time: 3s\n",
      "Epoch [77/500], Batch [8/8], Loss: 0.0727662593126297, Time: 3s\n",
      "Epoch [78/500], Batch [8/8], Loss: 0.08519702404737473, Time: 2s\n",
      "Epoch [79/500], Batch [8/8], Loss: 0.07213342189788818, Time: 2s\n",
      "Epoch [80/500], Batch [8/8], Loss: 0.07120687514543533, Time: 2s\n",
      "Epoch [81/500], Batch [8/8], Loss: 0.07232978940010071, Time: 2s\n",
      "Epoch [82/500], Batch [8/8], Loss: 0.07042471319437027, Time: 3s\n",
      "Epoch [83/500], Batch [8/8], Loss: 0.0718352422118187, Time: 2s\n",
      "Epoch [84/500], Batch [8/8], Loss: 0.07354274392127991, Time: 3s\n",
      "Epoch [85/500], Batch [8/8], Loss: 0.07289907336235046, Time: 3s\n",
      "Epoch [86/500], Batch [8/8], Loss: 0.07257477194070816, Time: 2s\n",
      "Epoch [87/500], Batch [8/8], Loss: 0.07213373482227325, Time: 3s\n",
      "Epoch [88/500], Batch [8/8], Loss: 0.06937233358621597, Time: 2s\n",
      "Epoch [89/500], Batch [8/8], Loss: 0.07101621478796005, Time: 3s\n",
      "Epoch [90/500], Batch [8/8], Loss: 0.0731206014752388, Time: 3s\n",
      "Epoch [91/500], Batch [8/8], Loss: 0.08742404729127884, Time: 3s\n",
      "Epoch [92/500], Batch [8/8], Loss: 0.07262316346168518, Time: 2s\n",
      "Epoch [93/500], Batch [8/8], Loss: 0.07045357674360275, Time: 3s\n",
      "Epoch [94/500], Batch [8/8], Loss: 0.07199828326702118, Time: 3s\n",
      "Epoch [95/500], Batch [8/8], Loss: 0.07205662876367569, Time: 3s\n",
      "Epoch [96/500], Batch [8/8], Loss: 0.0723908394575119, Time: 3s\n",
      "Epoch [97/500], Batch [8/8], Loss: 0.07017291337251663, Time: 3s\n",
      "Epoch [98/500], Batch [8/8], Loss: 0.07310998439788818, Time: 2s\n",
      "Epoch [99/500], Batch [8/8], Loss: 0.07131180167198181, Time: 3s\n",
      "Epoch [100/500], Batch [8/8], Loss: 0.07226146012544632, Time: 2s\n",
      "Epoch [101/500], Batch [8/8], Loss: 0.08463475853204727, Time: 2s\n",
      "Epoch [102/500], Batch [8/8], Loss: 0.07110243290662766, Time: 3s\n",
      "Epoch [103/500], Batch [8/8], Loss: 0.07388808578252792, Time: 3s\n",
      "Epoch [104/500], Batch [8/8], Loss: 0.07141400873661041, Time: 3s\n",
      "Epoch [105/500], Batch [8/8], Loss: 0.07206977158784866, Time: 3s\n",
      "Epoch [106/500], Batch [8/8], Loss: 0.07238943874835968, Time: 2s\n",
      "Epoch [107/500], Batch [8/8], Loss: 0.07065262645483017, Time: 3s\n",
      "Epoch [108/500], Batch [8/8], Loss: 0.08664113283157349, Time: 3s\n",
      "Epoch [109/500], Batch [8/8], Loss: 0.07330898940563202, Time: 3s\n",
      "Epoch [110/500], Batch [8/8], Loss: 0.07084634900093079, Time: 3s\n",
      "Epoch [111/500], Batch [8/8], Loss: 0.07092288136482239, Time: 3s\n",
      "Epoch [112/500], Batch [8/8], Loss: 0.07121429592370987, Time: 3s\n",
      "Epoch [113/500], Batch [8/8], Loss: 0.07356135547161102, Time: 3s\n",
      "Epoch [114/500], Batch [8/8], Loss: 0.07179440557956696, Time: 3s\n",
      "Epoch [115/500], Batch [8/8], Loss: 0.08473793417215347, Time: 3s\n",
      "Epoch [116/500], Batch [8/8], Loss: 0.07346442341804504, Time: 3s\n",
      "Epoch [117/500], Batch [8/8], Loss: 0.0724034309387207, Time: 3s\n",
      "Epoch [118/500], Batch [8/8], Loss: 0.07196153700351715, Time: 3s\n",
      "Epoch [119/500], Batch [8/8], Loss: 0.08459798246622086, Time: 3s\n",
      "Epoch [120/500], Batch [8/8], Loss: 0.07023786008358002, Time: 3s\n",
      "Epoch [121/500], Batch [8/8], Loss: 0.07181570678949356, Time: 3s\n",
      "Epoch [122/500], Batch [8/8], Loss: 0.08604509383440018, Time: 3s\n",
      "Epoch [123/500], Batch [8/8], Loss: 0.07292601466178894, Time: 3s\n",
      "Epoch [124/500], Batch [8/8], Loss: 0.08533673733472824, Time: 3s\n",
      "Epoch [125/500], Batch [8/8], Loss: 0.07087014615535736, Time: 3s\n",
      "Epoch [126/500], Batch [8/8], Loss: 0.0712389275431633, Time: 3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [127/500], Batch [8/8], Loss: 0.07065501064062119, Time: 3s\n",
      "Epoch [128/500], Batch [8/8], Loss: 0.0856100469827652, Time: 3s\n",
      "Epoch [129/500], Batch [8/8], Loss: 0.07229354977607727, Time: 3s\n",
      "Epoch [130/500], Batch [8/8], Loss: 0.07083194702863693, Time: 3s\n",
      "Epoch [131/500], Batch [8/8], Loss: 0.07003071159124374, Time: 3s\n",
      "Epoch [132/500], Batch [8/8], Loss: 0.06964144110679626, Time: 3s\n",
      "Epoch [133/500], Batch [8/8], Loss: 0.08461931347846985, Time: 3s\n",
      "Epoch [134/500], Batch [8/8], Loss: 0.0700390413403511, Time: 3s\n",
      "Epoch [135/500], Batch [8/8], Loss: 0.07076244056224823, Time: 3s\n",
      "Epoch [136/500], Batch [8/8], Loss: 0.08580444008111954, Time: 3s\n",
      "Epoch [137/500], Batch [8/8], Loss: 0.07076889276504517, Time: 3s\n",
      "Epoch [138/500], Batch [8/8], Loss: 0.06920912116765976, Time: 3s\n",
      "Epoch [139/500], Batch [8/8], Loss: 0.07188637554645538, Time: 3s\n",
      "Epoch [140/500], Batch [8/8], Loss: 0.0708557739853859, Time: 3s\n",
      "Epoch [141/500], Batch [8/8], Loss: 0.08401148021221161, Time: 3s\n",
      "Epoch [142/500], Batch [8/8], Loss: 0.08352624624967575, Time: 3s\n",
      "Epoch [143/500], Batch [8/8], Loss: 0.07005926221609116, Time: 3s\n",
      "Epoch [144/500], Batch [8/8], Loss: 0.06940307468175888, Time: 2s\n",
      "Epoch [145/500], Batch [8/8], Loss: 0.0707959532737732, Time: 3s\n",
      "Epoch [146/500], Batch [8/8], Loss: 0.06953895837068558, Time: 3s\n",
      "Epoch [147/500], Batch [8/8], Loss: 0.06922788172960281, Time: 3s\n",
      "Epoch [148/500], Batch [8/8], Loss: 0.06964007765054703, Time: 3s\n",
      "Epoch [149/500], Batch [8/8], Loss: 0.08500955998897552, Time: 3s\n",
      "Epoch [150/500], Batch [8/8], Loss: 0.07163557410240173, Time: 3s\n",
      "Epoch [151/500], Batch [8/8], Loss: 0.07116315513849258, Time: 3s\n",
      "Epoch [152/500], Batch [8/8], Loss: 0.0702216625213623, Time: 3s\n",
      "Epoch [153/500], Batch [8/8], Loss: 0.07078816741704941, Time: 3s\n",
      "Epoch [154/500], Batch [8/8], Loss: 0.08252369612455368, Time: 3s\n",
      "Epoch [155/500], Batch [8/8], Loss: 0.06971835345029831, Time: 3s\n",
      "Epoch [156/500], Batch [8/8], Loss: 0.07221341878175735, Time: 3s\n",
      "Epoch [157/500], Batch [8/8], Loss: 0.07085554301738739, Time: 3s\n",
      "Epoch [158/500], Batch [8/8], Loss: 0.06914936006069183, Time: 3s\n",
      "Epoch [159/500], Batch [8/8], Loss: 0.07007237523794174, Time: 3s\n",
      "Epoch [160/500], Batch [8/8], Loss: 0.07097391784191132, Time: 3s\n",
      "Epoch [161/500], Batch [8/8], Loss: 0.07202781736850739, Time: 3s\n",
      "Epoch [162/500], Batch [8/8], Loss: 0.07032164186239243, Time: 3s\n",
      "Epoch [163/500], Batch [8/8], Loss: 0.0700574517250061, Time: 3s\n",
      "Epoch [164/500], Batch [8/8], Loss: 0.07011936604976654, Time: 3s\n",
      "Epoch [165/500], Batch [8/8], Loss: 0.06903354823589325, Time: 3s\n",
      "Epoch [166/500], Batch [8/8], Loss: 0.07000905275344849, Time: 3s\n",
      "Epoch [167/500], Batch [8/8], Loss: 0.0703376904129982, Time: 3s\n",
      "Epoch [168/500], Batch [8/8], Loss: 0.06900542229413986, Time: 3s\n",
      "Epoch [169/500], Batch [8/8], Loss: 0.06878487765789032, Time: 3s\n",
      "Epoch [170/500], Batch [8/8], Loss: 0.06880263239145279, Time: 3s\n",
      "Epoch [171/500], Batch [8/8], Loss: 0.06768225878477097, Time: 3s\n",
      "Epoch [172/500], Batch [8/8], Loss: 0.07124581933021545, Time: 3s\n",
      "Epoch [173/500], Batch [8/8], Loss: 0.0707523301243782, Time: 3s\n",
      "Epoch [174/500], Batch [8/8], Loss: 0.06807003915309906, Time: 3s\n",
      "Epoch [175/500], Batch [8/8], Loss: 0.06899186223745346, Time: 3s\n",
      "Epoch [176/500], Batch [8/8], Loss: 0.06843588501214981, Time: 3s\n",
      "Epoch [177/500], Batch [8/8], Loss: 0.07186666131019592, Time: 3s\n",
      "Epoch [178/500], Batch [8/8], Loss: 0.06973684579133987, Time: 3s\n",
      "Epoch [179/500], Batch [8/8], Loss: 0.0691654309630394, Time: 3s\n",
      "Epoch [180/500], Batch [8/8], Loss: 0.0821111723780632, Time: 3s\n",
      "Epoch [181/500], Batch [8/8], Loss: 0.07032965123653412, Time: 3s\n",
      "Epoch [182/500], Batch [8/8], Loss: 0.06936938315629959, Time: 3s\n",
      "Epoch [183/500], Batch [8/8], Loss: 0.06865748018026352, Time: 3s\n",
      "Epoch [184/500], Batch [8/8], Loss: 0.08330471068620682, Time: 3s\n",
      "Epoch [185/500], Batch [8/8], Loss: 0.06904906779527664, Time: 3s\n",
      "Epoch [186/500], Batch [8/8], Loss: 0.06885764002799988, Time: 3s\n",
      "Epoch [187/500], Batch [8/8], Loss: 0.08348216116428375, Time: 3s\n",
      "Epoch [188/500], Batch [8/8], Loss: 0.06964491307735443, Time: 3s\n",
      "Epoch [189/500], Batch [8/8], Loss: 0.06960180401802063, Time: 3s\n",
      "Epoch [190/500], Batch [8/8], Loss: 0.07101823389530182, Time: 3s\n",
      "Epoch [191/500], Batch [8/8], Loss: 0.07030609250068665, Time: 3s\n",
      "Epoch [192/500], Batch [8/8], Loss: 0.07005871832370758, Time: 3s\n",
      "Epoch [193/500], Batch [8/8], Loss: 0.07021190226078033, Time: 3s\n",
      "Epoch [194/500], Batch [8/8], Loss: 0.06945650279521942, Time: 3s\n",
      "Epoch [195/500], Batch [8/8], Loss: 0.06864477694034576, Time: 3s\n",
      "Epoch [196/500], Batch [8/8], Loss: 0.08417711406946182, Time: 3s\n",
      "Epoch [197/500], Batch [8/8], Loss: 0.07088085263967514, Time: 3s\n",
      "Epoch [198/500], Batch [8/8], Loss: 0.07007375359535217, Time: 3s\n",
      "Epoch [199/500], Batch [8/8], Loss: 0.06882067769765854, Time: 3s\n",
      "Epoch [200/500], Batch [8/8], Loss: 0.07019191980361938, Time: 3s\n",
      "Epoch [201/500], Batch [8/8], Loss: 0.07003296166658401, Time: 3s\n",
      "Epoch [202/500], Batch [8/8], Loss: 0.069129578769207, Time: 3s\n",
      "Epoch [203/500], Batch [8/8], Loss: 0.06776690483093262, Time: 3s\n",
      "Epoch [204/500], Batch [8/8], Loss: 0.06799821555614471, Time: 3s\n",
      "Epoch [205/500], Batch [8/8], Loss: 0.06722104549407959, Time: 3s\n",
      "Epoch [206/500], Batch [8/8], Loss: 0.06785868108272552, Time: 3s\n",
      "Epoch [207/500], Batch [8/8], Loss: 0.07060472667217255, Time: 3s\n",
      "Epoch [208/500], Batch [8/8], Loss: 0.06908545643091202, Time: 3s\n",
      "Epoch [209/500], Batch [8/8], Loss: 0.06787072122097015, Time: 3s\n",
      "Epoch [210/500], Batch [8/8], Loss: 0.06883792579174042, Time: 3s\n",
      "Epoch [211/500], Batch [8/8], Loss: 0.0696583241224289, Time: 3s\n",
      "Epoch [212/500], Batch [8/8], Loss: 0.08223960548639297, Time: 3s\n",
      "Epoch [213/500], Batch [8/8], Loss: 0.06855234503746033, Time: 3s\n",
      "Epoch [214/500], Batch [8/8], Loss: 0.06822288036346436, Time: 3s\n",
      "Epoch [215/500], Batch [8/8], Loss: 0.06955726444721222, Time: 3s\n",
      "Epoch [216/500], Batch [8/8], Loss: 0.06903962045907974, Time: 3s\n",
      "Epoch [217/500], Batch [8/8], Loss: 0.07018529623746872, Time: 3s\n",
      "Epoch [218/500], Batch [8/8], Loss: 0.06974219530820847, Time: 3s\n",
      "Epoch [219/500], Batch [8/8], Loss: 0.06869853287935257, Time: 3s\n",
      "Epoch [220/500], Batch [8/8], Loss: 0.06802398711442947, Time: 3s\n",
      "Epoch [221/500], Batch [8/8], Loss: 0.06942915916442871, Time: 3s\n",
      "Epoch [222/500], Batch [8/8], Loss: 0.06866315007209778, Time: 3s\n",
      "Epoch [223/500], Batch [8/8], Loss: 0.06844261288642883, Time: 3s\n",
      "Epoch [224/500], Batch [8/8], Loss: 0.06858404725790024, Time: 3s\n",
      "Epoch [225/500], Batch [8/8], Loss: 0.06905342638492584, Time: 3s\n",
      "Epoch [226/500], Batch [8/8], Loss: 0.06884903460741043, Time: 3s\n",
      "Epoch [227/500], Batch [8/8], Loss: 0.06856638193130493, Time: 3s\n",
      "Epoch [228/500], Batch [8/8], Loss: 0.06744756549596786, Time: 3s\n",
      "Epoch [229/500], Batch [8/8], Loss: 0.08341233432292938, Time: 3s\n",
      "Epoch [230/500], Batch [8/8], Loss: 0.08348377048969269, Time: 3s\n",
      "Epoch [231/500], Batch [8/8], Loss: 0.08180191367864609, Time: 3s\n",
      "Epoch [232/500], Batch [8/8], Loss: 0.06769507378339767, Time: 3s\n",
      "Epoch [233/500], Batch [8/8], Loss: 0.06856521964073181, Time: 3s\n",
      "Epoch [234/500], Batch [8/8], Loss: 0.06803479790687561, Time: 3s\n",
      "Epoch [235/500], Batch [8/8], Loss: 0.07050783932209015, Time: 3s\n",
      "Epoch [236/500], Batch [8/8], Loss: 0.06803551316261292, Time: 3s\n",
      "Epoch [237/500], Batch [8/8], Loss: 0.07104966789484024, Time: 3s\n",
      "Epoch [238/500], Batch [8/8], Loss: 0.06920232623815536, Time: 3s\n",
      "Epoch [239/500], Batch [8/8], Loss: 0.06940948963165283, Time: 3s\n",
      "Epoch [240/500], Batch [8/8], Loss: 0.06864292919635773, Time: 3s\n",
      "Epoch [241/500], Batch [8/8], Loss: 0.06977679580450058, Time: 3s\n",
      "Epoch [242/500], Batch [8/8], Loss: 0.06781187653541565, Time: 3s\n",
      "Epoch [243/500], Batch [8/8], Loss: 0.07134641706943512, Time: 3s\n",
      "Epoch [244/500], Batch [8/8], Loss: 0.06816263496875763, Time: 3s\n",
      "Epoch [245/500], Batch [8/8], Loss: 0.06871664524078369, Time: 3s\n",
      "Epoch [246/500], Batch [8/8], Loss: 0.06895441561937332, Time: 3s\n",
      "Epoch [247/500], Batch [8/8], Loss: 0.06863592565059662, Time: 3s\n",
      "Epoch [248/500], Batch [8/8], Loss: 0.06906789541244507, Time: 3s\n",
      "Epoch [249/500], Batch [8/8], Loss: 0.06860054284334183, Time: 3s\n",
      "Epoch [250/500], Batch [8/8], Loss: 0.06837228685617447, Time: 3s\n",
      "Epoch [251/500], Batch [8/8], Loss: 0.07078950852155685, Time: 3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [252/500], Batch [8/8], Loss: 0.06822945922613144, Time: 3s\n",
      "Epoch [253/500], Batch [8/8], Loss: 0.0678425058722496, Time: 3s\n",
      "Epoch [254/500], Batch [8/8], Loss: 0.0702311173081398, Time: 3s\n",
      "Epoch [255/500], Batch [8/8], Loss: 0.06763455271720886, Time: 3s\n",
      "Epoch [256/500], Batch [8/8], Loss: 0.06772181391716003, Time: 3s\n",
      "Epoch [257/500], Batch [8/8], Loss: 0.06951819360256195, Time: 3s\n",
      "Epoch [258/500], Batch [8/8], Loss: 0.06740855425596237, Time: 3s\n",
      "Epoch [259/500], Batch [8/8], Loss: 0.06897789984941483, Time: 3s\n",
      "Epoch [260/500], Batch [8/8], Loss: 0.06841778755187988, Time: 3s\n",
      "Epoch [261/500], Batch [8/8], Loss: 0.06834544241428375, Time: 3s\n",
      "Epoch [262/500], Batch [8/8], Loss: 0.06825301796197891, Time: 3s\n",
      "Epoch [263/500], Batch [8/8], Loss: 0.06795068085193634, Time: 3s\n",
      "Epoch [264/500], Batch [8/8], Loss: 0.06989441066980362, Time: 3s\n",
      "Epoch [265/500], Batch [8/8], Loss: 0.06794141978025436, Time: 3s\n",
      "Epoch [266/500], Batch [8/8], Loss: 0.06839880347251892, Time: 3s\n",
      "Epoch [267/500], Batch [8/8], Loss: 0.0806136280298233, Time: 3s\n",
      "Epoch [268/500], Batch [8/8], Loss: 0.08244969695806503, Time: 3s\n",
      "Epoch [269/500], Batch [8/8], Loss: 0.07147402316331863, Time: 3s\n",
      "Epoch [270/500], Batch [8/8], Loss: 0.06858202069997787, Time: 3s\n",
      "Epoch [271/500], Batch [8/8], Loss: 0.0686318576335907, Time: 3s\n",
      "Epoch [272/500], Batch [8/8], Loss: 0.06826440989971161, Time: 3s\n",
      "Epoch [273/500], Batch [8/8], Loss: 0.0688949003815651, Time: 3s\n",
      "Epoch [274/500], Batch [8/8], Loss: 0.06698097288608551, Time: 3s\n",
      "Epoch [275/500], Batch [8/8], Loss: 0.0691336914896965, Time: 3s\n",
      "Epoch [276/500], Batch [8/8], Loss: 0.0681048333644867, Time: 3s\n",
      "Epoch [277/500], Batch [8/8], Loss: 0.06803705543279648, Time: 3s\n",
      "Epoch [278/500], Batch [8/8], Loss: 0.07012391090393066, Time: 3s\n",
      "Epoch [279/500], Batch [8/8], Loss: 0.06779014319181442, Time: 3s\n",
      "Epoch [280/500], Batch [8/8], Loss: 0.06813296675682068, Time: 3s\n",
      "Epoch [281/500], Batch [8/8], Loss: 0.06879669427871704, Time: 3s\n",
      "Epoch [282/500], Batch [8/8], Loss: 0.06865910440683365, Time: 3s\n",
      "Epoch [283/500], Batch [8/8], Loss: 0.06835400313138962, Time: 3s\n",
      "Epoch [284/500], Batch [8/8], Loss: 0.06837808340787888, Time: 3s\n",
      "Epoch [285/500], Batch [8/8], Loss: 0.06754569709300995, Time: 3s\n",
      "Epoch [286/500], Batch [8/8], Loss: 0.0686211809515953, Time: 3s\n",
      "Epoch [287/500], Batch [8/8], Loss: 0.0829988494515419, Time: 3s\n",
      "Epoch [288/500], Batch [8/8], Loss: 0.06892336905002594, Time: 3s\n",
      "Epoch [289/500], Batch [8/8], Loss: 0.0684366449713707, Time: 3s\n",
      "Epoch [290/500], Batch [8/8], Loss: 0.06805853545665741, Time: 3s\n",
      "Epoch [291/500], Batch [8/8], Loss: 0.06829704344272614, Time: 3s\n",
      "Epoch [292/500], Batch [8/8], Loss: 0.06870068609714508, Time: 3s\n",
      "Epoch [293/500], Batch [8/8], Loss: 0.08220288157463074, Time: 3s\n",
      "Epoch [294/500], Batch [8/8], Loss: 0.06964795291423798, Time: 3s\n",
      "Epoch [295/500], Batch [8/8], Loss: 0.0684748962521553, Time: 3s\n",
      "Epoch [296/500], Batch [8/8], Loss: 0.06932280957698822, Time: 3s\n",
      "Epoch [297/500], Batch [8/8], Loss: 0.08172537386417389, Time: 3s\n",
      "Epoch [298/500], Batch [8/8], Loss: 0.06803970038890839, Time: 3s\n",
      "Epoch [299/500], Batch [8/8], Loss: 0.06821294128894806, Time: 3s\n",
      "Epoch [300/500], Batch [8/8], Loss: 0.06720909476280212, Time: 3s\n",
      "Epoch [301/500], Batch [8/8], Loss: 0.07025865465402603, Time: 3s\n",
      "Epoch [302/500], Batch [8/8], Loss: 0.06715268641710281, Time: 3s\n",
      "Epoch [303/500], Batch [8/8], Loss: 0.0680927187204361, Time: 3s\n",
      "Epoch [304/500], Batch [8/8], Loss: 0.06816646456718445, Time: 3s\n",
      "Epoch [305/500], Batch [8/8], Loss: 0.06906101852655411, Time: 3s\n",
      "Epoch [306/500], Batch [8/8], Loss: 0.0690239891409874, Time: 3s\n",
      "Epoch [307/500], Batch [8/8], Loss: 0.06869856268167496, Time: 3s\n",
      "Epoch [308/500], Batch [8/8], Loss: 0.06797011196613312, Time: 3s\n",
      "Epoch [309/500], Batch [8/8], Loss: 0.0670233964920044, Time: 3s\n",
      "Epoch [310/500], Batch [8/8], Loss: 0.06813967972993851, Time: 3s\n",
      "Epoch [311/500], Batch [8/8], Loss: 0.06917694211006165, Time: 3s\n",
      "Epoch [312/500], Batch [8/8], Loss: 0.06854773312807083, Time: 3s\n",
      "Epoch [313/500], Batch [8/8], Loss: 0.0711255818605423, Time: 3s\n",
      "Epoch [314/500], Batch [8/8], Loss: 0.08136515319347382, Time: 3s\n",
      "Epoch [315/500], Batch [8/8], Loss: 0.0685894712805748, Time: 3s\n",
      "Epoch [316/500], Batch [8/8], Loss: 0.06757504492998123, Time: 3s\n",
      "Epoch [317/500], Batch [8/8], Loss: 0.06693971157073975, Time: 3s\n",
      "Epoch [318/500], Batch [8/8], Loss: 0.06834010779857635, Time: 3s\n",
      "Epoch [319/500], Batch [8/8], Loss: 0.06865822523832321, Time: 3s\n",
      "Epoch [320/500], Batch [8/8], Loss: 0.06809306889772415, Time: 3s\n",
      "Epoch [321/500], Batch [8/8], Loss: 0.06993354856967926, Time: 3s\n",
      "Epoch [322/500], Batch [8/8], Loss: 0.06941236555576324, Time: 3s\n",
      "Epoch [323/500], Batch [8/8], Loss: 0.08217767626047134, Time: 3s\n",
      "Epoch [324/500], Batch [8/8], Loss: 0.0685499906539917, Time: 3s\n",
      "Epoch [325/500], Batch [8/8], Loss: 0.06950008869171143, Time: 3s\n",
      "Epoch [326/500], Batch [8/8], Loss: 0.06795856356620789, Time: 3s\n",
      "Epoch [327/500], Batch [8/8], Loss: 0.06862758100032806, Time: 3s\n",
      "Epoch [328/500], Batch [8/8], Loss: 0.06935965269804001, Time: 3s\n",
      "Epoch [329/500], Batch [8/8], Loss: 0.06932076811790466, Time: 3s\n",
      "Epoch [330/500], Batch [8/8], Loss: 0.06984547525644302, Time: 3s\n",
      "Epoch [331/500], Batch [8/8], Loss: 0.06692731380462646, Time: 3s\n",
      "Epoch [332/500], Batch [8/8], Loss: 0.06857655942440033, Time: 3s\n",
      "Epoch [333/500], Batch [8/8], Loss: 0.06938858330249786, Time: 3s\n",
      "Epoch [334/500], Batch [8/8], Loss: 0.07016558945178986, Time: 3s\n",
      "Epoch [335/500], Batch [8/8], Loss: 0.06918604671955109, Time: 3s\n",
      "Epoch [336/500], Batch [8/8], Loss: 0.06978331506252289, Time: 3s\n",
      "Epoch [337/500], Batch [8/8], Loss: 0.06952501833438873, Time: 3s\n",
      "Epoch [338/500], Batch [8/8], Loss: 0.06717526912689209, Time: 3s\n",
      "Epoch [339/500], Batch [8/8], Loss: 0.0676925778388977, Time: 3s\n",
      "Epoch [340/500], Batch [8/8], Loss: 0.06825781613588333, Time: 3s\n",
      "Epoch [341/500], Batch [8/8], Loss: 0.0816069021821022, Time: 3s\n",
      "Epoch [342/500], Batch [8/8], Loss: 0.0700351893901825, Time: 3s\n",
      "Epoch [343/500], Batch [8/8], Loss: 0.06911280006170273, Time: 3s\n",
      "Epoch [344/500], Batch [8/8], Loss: 0.06824953854084015, Time: 3s\n",
      "Epoch [345/500], Batch [8/8], Loss: 0.06780238449573517, Time: 3s\n",
      "Epoch [346/500], Batch [8/8], Loss: 0.07002133876085281, Time: 3s\n",
      "Epoch [347/500], Batch [8/8], Loss: 0.06666857749223709, Time: 3s\n",
      "Epoch [348/500], Batch [8/8], Loss: 0.06795122474431992, Time: 3s\n",
      "Epoch [349/500], Batch [8/8], Loss: 0.06728015840053558, Time: 3s\n",
      "Epoch [350/500], Batch [8/8], Loss: 0.06880776584148407, Time: 3s\n",
      "Epoch [351/500], Batch [8/8], Loss: 0.06842738389968872, Time: 3s\n",
      "Epoch [352/500], Batch [8/8], Loss: 0.0697210282087326, Time: 3s\n",
      "Epoch [353/500], Batch [8/8], Loss: 0.06789213418960571, Time: 3s\n",
      "Epoch [354/500], Batch [8/8], Loss: 0.0686628669500351, Time: 3s\n",
      "Epoch [355/500], Batch [8/8], Loss: 0.06886978447437286, Time: 3s\n",
      "Epoch [356/500], Batch [8/8], Loss: 0.06737354397773743, Time: 3s\n",
      "Epoch [357/500], Batch [8/8], Loss: 0.08117000013589859, Time: 3s\n",
      "Epoch [358/500], Batch [8/8], Loss: 0.06929517537355423, Time: 3s\n",
      "Epoch [359/500], Batch [8/8], Loss: 0.0688101276755333, Time: 3s\n",
      "Epoch [360/500], Batch [8/8], Loss: 0.06909365206956863, Time: 3s\n",
      "Epoch [361/500], Batch [8/8], Loss: 0.06764840334653854, Time: 3s\n",
      "Epoch [362/500], Batch [8/8], Loss: 0.06905081868171692, Time: 3s\n",
      "Epoch [363/500], Batch [8/8], Loss: 0.06983198970556259, Time: 3s\n",
      "Epoch [364/500], Batch [8/8], Loss: 0.06868734210729599, Time: 3s\n",
      "Epoch [365/500], Batch [8/8], Loss: 0.0686306282877922, Time: 3s\n",
      "Epoch [366/500], Batch [8/8], Loss: 0.06739552319049835, Time: 3s\n",
      "Epoch [367/500], Batch [8/8], Loss: 0.06770893186330795, Time: 3s\n",
      "Epoch [368/500], Batch [8/8], Loss: 0.0690574124455452, Time: 3s\n",
      "Epoch [369/500], Batch [8/8], Loss: 0.06853974610567093, Time: 3s\n",
      "Epoch [370/500], Batch [8/8], Loss: 0.06818198412656784, Time: 3s\n",
      "Epoch [371/500], Batch [8/8], Loss: 0.0689273253083229, Time: 3s\n",
      "Epoch [372/500], Batch [8/8], Loss: 0.06799297779798508, Time: 3s\n",
      "Epoch [373/500], Batch [8/8], Loss: 0.0695379450917244, Time: 3s\n",
      "Epoch [374/500], Batch [8/8], Loss: 0.06774783879518509, Time: 3s\n",
      "Epoch [375/500], Batch [8/8], Loss: 0.08217257261276245, Time: 3s\n",
      "Epoch [376/500], Batch [8/8], Loss: 0.06924739480018616, Time: 3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [377/500], Batch [8/8], Loss: 0.06725715100765228, Time: 3s\n",
      "Epoch [378/500], Batch [8/8], Loss: 0.06747891008853912, Time: 3s\n",
      "Epoch [379/500], Batch [8/8], Loss: 0.06878826767206192, Time: 3s\n",
      "Epoch [380/500], Batch [8/8], Loss: 0.06824284791946411, Time: 3s\n",
      "Epoch [381/500], Batch [8/8], Loss: 0.0682704970240593, Time: 3s\n",
      "Epoch [382/500], Batch [8/8], Loss: 0.06733956933021545, Time: 3s\n",
      "Epoch [383/500], Batch [8/8], Loss: 0.06729335337877274, Time: 3s\n",
      "Epoch [384/500], Batch [8/8], Loss: 0.06829323619604111, Time: 3s\n",
      "Epoch [385/500], Batch [8/8], Loss: 0.06845666468143463, Time: 3s\n",
      "Epoch [386/500], Batch [8/8], Loss: 0.06885914504528046, Time: 3s\n",
      "Epoch [387/500], Batch [8/8], Loss: 0.06752598285675049, Time: 3s\n",
      "Epoch [388/500], Batch [8/8], Loss: 0.06786079704761505, Time: 3s\n",
      "Epoch [389/500], Batch [8/8], Loss: 0.06957557052373886, Time: 3s\n",
      "Epoch [390/500], Batch [8/8], Loss: 0.06797117739915848, Time: 3s\n",
      "Epoch [391/500], Batch [8/8], Loss: 0.08261200040578842, Time: 3s\n",
      "Epoch [392/500], Batch [8/8], Loss: 0.06840937584638596, Time: 3s\n",
      "Epoch [393/500], Batch [8/8], Loss: 0.06712674349546432, Time: 3s\n",
      "Epoch [394/500], Batch [8/8], Loss: 0.06822701543569565, Time: 3s\n",
      "Epoch [395/500], Batch [8/8], Loss: 0.0661163479089737, Time: 3s\n",
      "Epoch [396/500], Batch [8/8], Loss: 0.06642147898674011, Time: 3s\n",
      "Epoch [397/500], Batch [8/8], Loss: 0.08287738263607025, Time: 3s\n",
      "Epoch [398/500], Batch [8/8], Loss: 0.0672420859336853, Time: 3s\n",
      "Epoch [399/500], Batch [8/8], Loss: 0.06950705498456955, Time: 3s\n",
      "Epoch [400/500], Batch [8/8], Loss: 0.06685701757669449, Time: 3s\n",
      "Epoch [401/500], Batch [8/8], Loss: 0.06552450358867645, Time: 3s\n",
      "Epoch [402/500], Batch [8/8], Loss: 0.06840384006500244, Time: 3s\n",
      "Epoch [403/500], Batch [8/8], Loss: 0.06762588024139404, Time: 3s\n",
      "Epoch [404/500], Batch [8/8], Loss: 0.06906849890947342, Time: 3s\n",
      "Epoch [405/500], Batch [8/8], Loss: 0.06708623468875885, Time: 3s\n",
      "Epoch [406/500], Batch [8/8], Loss: 0.06948745995759964, Time: 3s\n",
      "Epoch [407/500], Batch [8/8], Loss: 0.0670381560921669, Time: 3s\n",
      "Epoch [408/500], Batch [8/8], Loss: 0.06917165964841843, Time: 3s\n",
      "Epoch [409/500], Batch [8/8], Loss: 0.06774994730949402, Time: 3s\n",
      "Epoch [410/500], Batch [8/8], Loss: 0.06762563437223434, Time: 3s\n",
      "Epoch [411/500], Batch [8/8], Loss: 0.06847210973501205, Time: 3s\n",
      "Epoch [412/500], Batch [8/8], Loss: 0.06662651151418686, Time: 3s\n",
      "Epoch [413/500], Batch [8/8], Loss: 0.07003331929445267, Time: 3s\n",
      "Epoch [414/500], Batch [8/8], Loss: 0.06797095388174057, Time: 3s\n",
      "Epoch [415/500], Batch [8/8], Loss: 0.06841262429952621, Time: 3s\n",
      "Epoch [416/500], Batch [8/8], Loss: 0.06853377819061279, Time: 3s\n",
      "Epoch [417/500], Batch [8/8], Loss: 0.06830127537250519, Time: 3s\n",
      "Epoch [418/500], Batch [8/8], Loss: 0.0698140487074852, Time: 3s\n",
      "Epoch [419/500], Batch [8/8], Loss: 0.06806863844394684, Time: 3s\n",
      "Epoch [420/500], Batch [8/8], Loss: 0.06803471595048904, Time: 3s\n",
      "Epoch [421/500], Batch [8/8], Loss: 0.06974964588880539, Time: 3s\n",
      "Epoch [422/500], Batch [8/8], Loss: 0.06766945868730545, Time: 3s\n",
      "Epoch [423/500], Batch [8/8], Loss: 0.06811255216598511, Time: 3s\n",
      "Epoch [424/500], Batch [8/8], Loss: 0.06794977933168411, Time: 3s\n",
      "Epoch [425/500], Batch [8/8], Loss: 0.06935235857963562, Time: 3s\n",
      "Epoch [426/500], Batch [8/8], Loss: 0.06753931194543839, Time: 3s\n",
      "Epoch [427/500], Batch [8/8], Loss: 0.06729821860790253, Time: 3s\n",
      "Epoch [428/500], Batch [8/8], Loss: 0.06805184483528137, Time: 3s\n",
      "Epoch [429/500], Batch [8/8], Loss: 0.06982000172138214, Time: 3s\n",
      "Epoch [430/500], Batch [8/8], Loss: 0.06838855892419815, Time: 3s\n",
      "Epoch [431/500], Batch [8/8], Loss: 0.06836399435997009, Time: 3s\n",
      "Epoch [432/500], Batch [8/8], Loss: 0.06841538846492767, Time: 3s\n",
      "Epoch [433/500], Batch [8/8], Loss: 0.06677258014678955, Time: 3s\n",
      "Epoch [434/500], Batch [8/8], Loss: 0.07016938179731369, Time: 3s\n",
      "Epoch [435/500], Batch [8/8], Loss: 0.08115524053573608, Time: 3s\n",
      "Epoch [436/500], Batch [8/8], Loss: 0.06794507801532745, Time: 3s\n",
      "Epoch [437/500], Batch [8/8], Loss: 0.06916964799165726, Time: 3s\n",
      "Epoch [438/500], Batch [8/8], Loss: 0.0681600347161293, Time: 3s\n",
      "Epoch [439/500], Batch [8/8], Loss: 0.0684930756688118, Time: 3s\n",
      "Epoch [440/500], Batch [8/8], Loss: 0.06766467541456223, Time: 3s\n",
      "Epoch [441/500], Batch [8/8], Loss: 0.08028765767812729, Time: 3s\n",
      "Epoch [442/500], Batch [8/8], Loss: 0.07943545281887054, Time: 3s\n",
      "Epoch [443/500], Batch [8/8], Loss: 0.06838710606098175, Time: 3s\n",
      "Epoch [444/500], Batch [8/8], Loss: 0.06902728229761124, Time: 3s\n",
      "Epoch [445/500], Batch [8/8], Loss: 0.06593333184719086, Time: 3s\n",
      "Epoch [446/500], Batch [8/8], Loss: 0.08097413927316666, Time: 3s\n",
      "Epoch [447/500], Batch [8/8], Loss: 0.0692751407623291, Time: 3s\n",
      "Epoch [448/500], Batch [8/8], Loss: 0.0681099221110344, Time: 3s\n",
      "Epoch [449/500], Batch [8/8], Loss: 0.07034430652856827, Time: 3s\n",
      "Epoch [450/500], Batch [8/8], Loss: 0.06676638871431351, Time: 3s\n",
      "Epoch [451/500], Batch [8/8], Loss: 0.06723947077989578, Time: 3s\n",
      "Epoch [452/500], Batch [8/8], Loss: 0.06852711737155914, Time: 3s\n",
      "Epoch [453/500], Batch [8/8], Loss: 0.06769274920225143, Time: 3s\n",
      "Epoch [454/500], Batch [8/8], Loss: 0.06925291568040848, Time: 3s\n",
      "Epoch [455/500], Batch [8/8], Loss: 0.06690315902233124, Time: 3s\n",
      "Epoch [456/500], Batch [8/8], Loss: 0.06739229708909988, Time: 3s\n",
      "Epoch [457/500], Batch [8/8], Loss: 0.06935098022222519, Time: 3s\n",
      "Epoch [458/500], Batch [8/8], Loss: 0.06925106793642044, Time: 3s\n",
      "Epoch [459/500], Batch [8/8], Loss: 0.06833171844482422, Time: 3s\n",
      "Epoch [460/500], Batch [8/8], Loss: 0.06641032546758652, Time: 3s\n",
      "Epoch [461/500], Batch [8/8], Loss: 0.06778115034103394, Time: 3s\n",
      "Epoch [462/500], Batch [8/8], Loss: 0.07078469544649124, Time: 3s\n",
      "Epoch [463/500], Batch [8/8], Loss: 0.06669853627681732, Time: 3s\n",
      "Epoch [464/500], Batch [8/8], Loss: 0.06888896971940994, Time: 3s\n",
      "Epoch [465/500], Batch [8/8], Loss: 0.06955098360776901, Time: 3s\n",
      "Epoch [466/500], Batch [8/8], Loss: 0.07010877132415771, Time: 3s\n",
      "Epoch [467/500], Batch [8/8], Loss: 0.0695197805762291, Time: 3s\n",
      "Epoch [468/500], Batch [8/8], Loss: 0.06801624596118927, Time: 3s\n",
      "Epoch [469/500], Batch [8/8], Loss: 0.06848505884408951, Time: 3s\n",
      "Epoch [470/500], Batch [8/8], Loss: 0.0681074932217598, Time: 3s\n",
      "Epoch [471/500], Batch [8/8], Loss: 0.06813720613718033, Time: 3s\n",
      "Epoch [472/500], Batch [8/8], Loss: 0.0814468115568161, Time: 3s\n",
      "Epoch [473/500], Batch [8/8], Loss: 0.08195927739143372, Time: 3s\n",
      "Epoch [474/500], Batch [8/8], Loss: 0.06773581355810165, Time: 3s\n",
      "Epoch [475/500], Batch [8/8], Loss: 0.06828988343477249, Time: 3s\n",
      "Epoch [476/500], Batch [8/8], Loss: 0.06947407126426697, Time: 3s\n",
      "Epoch [477/500], Batch [8/8], Loss: 0.06669159978628159, Time: 3s\n",
      "Epoch [478/500], Batch [8/8], Loss: 0.06940382719039917, Time: 3s\n",
      "Epoch [479/500], Batch [8/8], Loss: 0.07016023248434067, Time: 3s\n",
      "Epoch [480/500], Batch [8/8], Loss: 0.06767095625400543, Time: 3s\n",
      "Epoch [481/500], Batch [8/8], Loss: 0.08059155195951462, Time: 3s\n",
      "Epoch [482/500], Batch [8/8], Loss: 0.06981942057609558, Time: 3s\n",
      "Epoch [483/500], Batch [8/8], Loss: 0.06837617605924606, Time: 3s\n",
      "Epoch [484/500], Batch [8/8], Loss: 0.0675097405910492, Time: 3s\n",
      "Epoch [485/500], Batch [8/8], Loss: 0.06861351430416107, Time: 3s\n",
      "Epoch [486/500], Batch [8/8], Loss: 0.0701032504439354, Time: 3s\n",
      "Epoch [487/500], Batch [8/8], Loss: 0.06854571402072906, Time: 3s\n",
      "Epoch [488/500], Batch [8/8], Loss: 0.06860047578811646, Time: 3s\n",
      "Epoch [489/500], Batch [8/8], Loss: 0.08210200071334839, Time: 3s\n",
      "Epoch [490/500], Batch [8/8], Loss: 0.06961186230182648, Time: 3s\n",
      "Epoch [491/500], Batch [8/8], Loss: 0.06934083253145218, Time: 3s\n",
      "Epoch [492/500], Batch [8/8], Loss: 0.06903230398893356, Time: 3s\n",
      "Epoch [493/500], Batch [8/8], Loss: 0.06875235587358475, Time: 3s\n",
      "Epoch [494/500], Batch [8/8], Loss: 0.06865596771240234, Time: 3s\n",
      "Epoch [495/500], Batch [8/8], Loss: 0.06693008542060852, Time: 3s\n",
      "Epoch [496/500], Batch [8/8], Loss: 0.08147919923067093, Time: 3s\n",
      "Epoch [497/500], Batch [8/8], Loss: 0.06877443939447403, Time: 3s\n",
      "Epoch [498/500], Batch [8/8], Loss: 0.06725846976041794, Time: 3s\n",
      "Epoch [499/500], Batch [8/8], Loss: 0.06934378296136856, Time: 3s\n",
      "Epoch [500/500], Batch [8/8], Loss: 0.068340003490448, Time: 3s\n",
      "Final loss: 0.08989188075065613\n",
      "CPU times: user 37min 56s, sys: 22min 38s, total: 1h 35s\n",
      "Wall time: 23min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "device='cpu'\n",
    "trained_model, loss_output = train.train_model(train_model_df, train_idx_map, batchSize=2000,\n",
    "                                               print_itr=8, numEpochs=500, model_cols=model_cols,\n",
    "                                               learningRate=0.00001, device=device, num_workers=10,\n",
    "                                               loss='L2', model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "66b8da77",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,y_train = clean_data.build_xy(train_model_df,train_idx_map)  # create input/label pair\n",
    "X_test,y_test = clean_data.build_xy(train_model_df,test_idx_map)  # create input/label pair\n",
    "y_train_pred = train.predict(trained_model, X_test, device=device) # get predictions for each train\n",
    "y_test_pred = train.predict(trained_model, X_test, device=device) # get predictions for each test\n",
    "y_train_pred_df = pd.DataFrame(y_train_pred, columns=train_model_df.columns[:-2])  # put results into a dataframe\n",
    "y_test_pred_df = pd.DataFrame(y_test_pred, columns=train_model_df.columns[:-2])  # put results into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cfcb4c82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Test set MAE (L1) loss: 0.1440299256315309\n",
      "    Test set MSE (L2) loss: 0.07443746599568021\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7efd87682c40>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(f'    Test set MAE (L1) loss: {mean_absolute_error(y_test, y_test_pred_df)}')\n",
    "print(f'    Test set MSE (L2) loss: {mean_squared_error(y_test, y_test_pred_df)}')\n",
    "\n",
    "plt.plot([float(l['loss']) for l in loss_output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b858a5ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Ground Truth:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BSTAR</th>\n",
       "      <th>INCLINATION</th>\n",
       "      <th>RA_OF_ASC_NODE</th>\n",
       "      <th>ECCENTRICITY</th>\n",
       "      <th>ARG_OF_PERICENTER</th>\n",
       "      <th>MEAN_ANOMALY</th>\n",
       "      <th>MEAN_MOTION</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000172</td>\n",
       "      <td>97.5891</td>\n",
       "      <td>89.2985</td>\n",
       "      <td>0.002764</td>\n",
       "      <td>129.1489</td>\n",
       "      <td>231.2266</td>\n",
       "      <td>14.932819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000089</td>\n",
       "      <td>97.8168</td>\n",
       "      <td>89.6696</td>\n",
       "      <td>0.000834</td>\n",
       "      <td>209.9726</td>\n",
       "      <td>150.1036</td>\n",
       "      <td>15.286642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000024</td>\n",
       "      <td>97.6766</td>\n",
       "      <td>51.2647</td>\n",
       "      <td>0.001438</td>\n",
       "      <td>77.8957</td>\n",
       "      <td>282.3697</td>\n",
       "      <td>15.130646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000022</td>\n",
       "      <td>97.6026</td>\n",
       "      <td>274.3799</td>\n",
       "      <td>0.002504</td>\n",
       "      <td>210.9792</td>\n",
       "      <td>148.9966</td>\n",
       "      <td>14.935562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000080</td>\n",
       "      <td>97.6403</td>\n",
       "      <td>357.2280</td>\n",
       "      <td>0.002655</td>\n",
       "      <td>126.3307</td>\n",
       "      <td>234.0389</td>\n",
       "      <td>14.940357</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      BSTAR  INCLINATION  RA_OF_ASC_NODE  ECCENTRICITY  ARG_OF_PERICENTER  \\\n",
       "0  0.000172      97.5891         89.2985      0.002764           129.1489   \n",
       "1  0.000089      97.8168         89.6696      0.000834           209.9726   \n",
       "2  0.000024      97.6766         51.2647      0.001438            77.8957   \n",
       "3  0.000022      97.6026        274.3799      0.002504           210.9792   \n",
       "4  0.000080      97.6403        357.2280      0.002655           126.3307   \n",
       "\n",
       "   MEAN_ANOMALY  MEAN_MOTION  \n",
       "0      231.2266    14.932819  \n",
       "1      150.1036    15.286642  \n",
       "2      282.3697    15.130646  \n",
       "3      148.9966    14.935562  \n",
       "4      234.0389    14.940357  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train - Prediction:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BSTAR</th>\n",
       "      <th>INCLINATION</th>\n",
       "      <th>RA_OF_ASC_NODE</th>\n",
       "      <th>ECCENTRICITY</th>\n",
       "      <th>ARG_OF_PERICENTER</th>\n",
       "      <th>MEAN_ANOMALY</th>\n",
       "      <th>MEAN_MOTION</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>96.209366</td>\n",
       "      <td>178.526703</td>\n",
       "      <td>0.001414</td>\n",
       "      <td>0.0</td>\n",
       "      <td>179.116516</td>\n",
       "      <td>15.081505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>97.814819</td>\n",
       "      <td>185.073669</td>\n",
       "      <td>0.000837</td>\n",
       "      <td>0.0</td>\n",
       "      <td>188.625916</td>\n",
       "      <td>15.318454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>97.424614</td>\n",
       "      <td>177.268341</td>\n",
       "      <td>0.002361</td>\n",
       "      <td>0.0</td>\n",
       "      <td>182.779800</td>\n",
       "      <td>14.940508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>96.506554</td>\n",
       "      <td>177.268219</td>\n",
       "      <td>0.002459</td>\n",
       "      <td>0.0</td>\n",
       "      <td>183.883728</td>\n",
       "      <td>14.859314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>98.545624</td>\n",
       "      <td>186.881546</td>\n",
       "      <td>0.001180</td>\n",
       "      <td>0.0</td>\n",
       "      <td>187.392365</td>\n",
       "      <td>15.214928</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   BSTAR  INCLINATION  RA_OF_ASC_NODE  ECCENTRICITY  ARG_OF_PERICENTER  \\\n",
       "0    0.0    96.209366      178.526703      0.001414                0.0   \n",
       "1    0.0    97.814819      185.073669      0.000837                0.0   \n",
       "2    0.0    97.424614      177.268341      0.002361                0.0   \n",
       "3    0.0    96.506554      177.268219      0.002459                0.0   \n",
       "4    0.0    98.545624      186.881546      0.001180                0.0   \n",
       "\n",
       "   MEAN_ANOMALY  MEAN_MOTION  \n",
       "0    179.116516    15.081505  \n",
       "1    188.625916    15.318454  \n",
       "2    182.779800    14.940508  \n",
       "3    183.883728    14.859314  \n",
       "4    187.392365    15.214928  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Train - Ground Truth:\")\n",
    "display(clean_data.normalize_all_columns(y_train.head().copy(), reverse=True))  # see ground truths\n",
    "print(\"Train - Prediction:\")\n",
    "display(clean_data.normalize_all_columns(y_train_pred_df.head().copy(), reverse=True))  # See predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "532c224a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test - Ground Truth:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BSTAR</th>\n",
       "      <th>INCLINATION</th>\n",
       "      <th>RA_OF_ASC_NODE</th>\n",
       "      <th>ECCENTRICITY</th>\n",
       "      <th>ARG_OF_PERICENTER</th>\n",
       "      <th>MEAN_ANOMALY</th>\n",
       "      <th>MEAN_MOTION</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000082</td>\n",
       "      <td>97.8050</td>\n",
       "      <td>48.8779</td>\n",
       "      <td>0.001378</td>\n",
       "      <td>135.9387</td>\n",
       "      <td>224.2943</td>\n",
       "      <td>15.116934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000018</td>\n",
       "      <td>97.7597</td>\n",
       "      <td>89.4993</td>\n",
       "      <td>0.000762</td>\n",
       "      <td>194.2864</td>\n",
       "      <td>165.8162</td>\n",
       "      <td>15.325618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.000011</td>\n",
       "      <td>97.7066</td>\n",
       "      <td>220.8896</td>\n",
       "      <td>0.002423</td>\n",
       "      <td>299.0911</td>\n",
       "      <td>60.7878</td>\n",
       "      <td>14.943407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000513</td>\n",
       "      <td>97.6230</td>\n",
       "      <td>292.2434</td>\n",
       "      <td>0.003217</td>\n",
       "      <td>93.4454</td>\n",
       "      <td>267.0406</td>\n",
       "      <td>14.848775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000122</td>\n",
       "      <td>97.6968</td>\n",
       "      <td>182.6337</td>\n",
       "      <td>0.001036</td>\n",
       "      <td>310.9958</td>\n",
       "      <td>195.4624</td>\n",
       "      <td>15.183424</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      BSTAR  INCLINATION  RA_OF_ASC_NODE  ECCENTRICITY  ARG_OF_PERICENTER  \\\n",
       "0  0.000082      97.8050         48.8779      0.001378           135.9387   \n",
       "1  0.000018      97.7597         89.4993      0.000762           194.2864   \n",
       "2 -0.000011      97.7066        220.8896      0.002423           299.0911   \n",
       "3  0.000513      97.6230        292.2434      0.003217            93.4454   \n",
       "4  0.000122      97.6968        182.6337      0.001036           310.9958   \n",
       "\n",
       "   MEAN_ANOMALY  MEAN_MOTION  \n",
       "0      224.2943    15.116934  \n",
       "1      165.8162    15.325618  \n",
       "2       60.7878    14.943407  \n",
       "3      267.0406    14.848775  \n",
       "4      195.4624    15.183424  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test - Prediction:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BSTAR</th>\n",
       "      <th>INCLINATION</th>\n",
       "      <th>RA_OF_ASC_NODE</th>\n",
       "      <th>ECCENTRICITY</th>\n",
       "      <th>ARG_OF_PERICENTER</th>\n",
       "      <th>MEAN_ANOMALY</th>\n",
       "      <th>MEAN_MOTION</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>96.209366</td>\n",
       "      <td>178.526703</td>\n",
       "      <td>0.001414</td>\n",
       "      <td>0.0</td>\n",
       "      <td>179.116516</td>\n",
       "      <td>15.081505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>97.814819</td>\n",
       "      <td>185.073669</td>\n",
       "      <td>0.000837</td>\n",
       "      <td>0.0</td>\n",
       "      <td>188.625916</td>\n",
       "      <td>15.318454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>97.424614</td>\n",
       "      <td>177.268341</td>\n",
       "      <td>0.002361</td>\n",
       "      <td>0.0</td>\n",
       "      <td>182.779800</td>\n",
       "      <td>14.940508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>96.506554</td>\n",
       "      <td>177.268219</td>\n",
       "      <td>0.002459</td>\n",
       "      <td>0.0</td>\n",
       "      <td>183.883728</td>\n",
       "      <td>14.859314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>98.545624</td>\n",
       "      <td>186.881546</td>\n",
       "      <td>0.001180</td>\n",
       "      <td>0.0</td>\n",
       "      <td>187.392365</td>\n",
       "      <td>15.214928</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   BSTAR  INCLINATION  RA_OF_ASC_NODE  ECCENTRICITY  ARG_OF_PERICENTER  \\\n",
       "0    0.0    96.209366      178.526703      0.001414                0.0   \n",
       "1    0.0    97.814819      185.073669      0.000837                0.0   \n",
       "2    0.0    97.424614      177.268341      0.002361                0.0   \n",
       "3    0.0    96.506554      177.268219      0.002459                0.0   \n",
       "4    0.0    98.545624      186.881546      0.001180                0.0   \n",
       "\n",
       "   MEAN_ANOMALY  MEAN_MOTION  \n",
       "0    179.116516    15.081505  \n",
       "1    188.625916    15.318454  \n",
       "2    182.779800    14.940508  \n",
       "3    183.883728    14.859314  \n",
       "4    187.392365    15.214928  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Test - Ground Truth:\")\n",
    "display(clean_data.normalize_all_columns(y_test.head().copy(), reverse=True))  # see ground truths\n",
    "print(\"Test - Prediction:\")\n",
    "display(clean_data.normalize_all_columns(y_pred_df.head().copy(), reverse=True))  # See predictions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
