{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "files = ['train']\n",
    "\n",
    "model_cols = ['BSTAR', 'INCLINATION', 'RA_OF_ASC_NODE', 'ECCENTRICITY', 'ARG_OF_PERICENTER', 'MEAN_ANOMALY',\n",
    "              'MEAN_MOTION', 'epoch_jd', 'epoch_fr',\n",
    "              #'MEAN_MOTION_DOT', 'MEAN_MOTION_DDOT', \n",
    "             ]\n",
    "\n",
    "#%time df = pd.read_pickle(os.environ['GP_HIST_PATH'] + '/raw_compiled/train.pkl' )  # Takes about 20s\n",
    "train_df = pd.read_pickle(os.environ['my_home_path'] + '/data/space-track-gp-hist-sample/raw_compiled/train.pkl' )\n",
    "test_df = pd.read_pickle(os.environ['my_home_path'] + '/data/space-track-gp-hist-sample/raw_compiled/test.pkl' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Percent of NORADs to use during training...\n",
    "perc = 0.5\n",
    "norad_count = int(len(train_df.NORAD_CAT_ID.unique()) * perc)\n",
    "train_df = train_df[train_df.NORAD_CAT_ID.isin(train_df.NORAD_CAT_ID.unique()[:norad_count])].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 1519/1519 [00:00<00:00, 2402.24it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 599/599 [00:00<00:00, 2692.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.32 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import clean_data\n",
    "\n",
    "for df in [train_df, test_df]:\n",
    "    df = clean_data.add_epoch_data(df)\n",
    "    df = clean_data.normalize_all_columns(df)\n",
    "    \n",
    "train_idx_map = clean_data.create_index_map(train_df)\n",
    "test_idx_map = clean_data.create_index_map(test_df)\n",
    "\n",
    "train_df = train_df[model_cols]\n",
    "test_df = test_df[model_cols]\n",
    "\n",
    "X_test,y_test = clean_data.build_xy(test_df,test_idx_map)  # create input/label pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Loading model\n",
      ">>> Loading dataset\n",
      ">>> Beginning training!\n",
      "Epoch [1/10], Batch [10/297], Loss: 0.41383862495422363, Time: 1s\n",
      "Epoch [1/10], Batch [20/297], Loss: 0.273721843957901, Time: 0s\n",
      "Epoch [1/10], Batch [30/297], Loss: 0.2569553256034851, Time: 0s\n",
      "Epoch [1/10], Batch [40/297], Loss: 0.2058221399784088, Time: 0s\n",
      "Epoch [1/10], Batch [50/297], Loss: 0.17379535734653473, Time: 0s\n",
      "Epoch [1/10], Batch [60/297], Loss: 0.13270550966262817, Time: 0s\n",
      "Epoch [1/10], Batch [70/297], Loss: 0.17171163856983185, Time: 0s\n",
      "Epoch [1/10], Batch [80/297], Loss: 0.11921536177396774, Time: 0s\n",
      "Epoch [1/10], Batch [90/297], Loss: 0.11288155615329742, Time: 0s\n",
      "Epoch [1/10], Batch [100/297], Loss: 0.08324187994003296, Time: 0s\n",
      "Epoch [1/10], Batch [110/297], Loss: 0.08921951055526733, Time: 0s\n",
      "Epoch [1/10], Batch [120/297], Loss: 0.08388017117977142, Time: 0s\n",
      "Epoch [1/10], Batch [130/297], Loss: 0.07992846518754959, Time: 0s\n",
      "Epoch [1/10], Batch [140/297], Loss: 0.06264731287956238, Time: 0s\n",
      "Epoch [1/10], Batch [150/297], Loss: 0.06714139133691788, Time: 0s\n",
      "Epoch [1/10], Batch [160/297], Loss: 0.07537751644849777, Time: 0s\n",
      "Epoch [1/10], Batch [170/297], Loss: 0.04973338544368744, Time: 0s\n",
      "Epoch [1/10], Batch [180/297], Loss: 0.05098451301455498, Time: 0s\n",
      "Epoch [1/10], Batch [190/297], Loss: 0.06946856528520584, Time: 0s\n",
      "Epoch [1/10], Batch [200/297], Loss: 0.08224038779735565, Time: 0s\n",
      "Epoch [1/10], Batch [210/297], Loss: 0.06575094908475876, Time: 0s\n",
      "Epoch [1/10], Batch [220/297], Loss: 0.04273947328329086, Time: 0s\n",
      "Epoch [1/10], Batch [230/297], Loss: 0.050054118037223816, Time: 0s\n",
      "Epoch [1/10], Batch [240/297], Loss: 0.04747670143842697, Time: 0s\n",
      "Epoch [1/10], Batch [250/297], Loss: 0.06267855316400528, Time: 0s\n",
      "Epoch [1/10], Batch [260/297], Loss: 0.044537268579006195, Time: 0s\n",
      "Epoch [1/10], Batch [270/297], Loss: 0.07221585512161255, Time: 0s\n",
      "Epoch [1/10], Batch [280/297], Loss: 0.05696925148367882, Time: 0s\n",
      "Epoch [1/10], Batch [290/297], Loss: 0.03953510522842407, Time: 0s\n",
      "Epoch [2/10], Batch [10/297], Loss: 0.04430130496621132, Time: 1s\n",
      "Epoch [2/10], Batch [20/297], Loss: 0.04931330680847168, Time: 0s\n",
      "Epoch [2/10], Batch [30/297], Loss: 0.037670694291591644, Time: 0s\n",
      "Epoch [2/10], Batch [40/297], Loss: 0.04417481645941734, Time: 0s\n",
      "Epoch [2/10], Batch [50/297], Loss: 0.04168090224266052, Time: 0s\n",
      "Epoch [2/10], Batch [60/297], Loss: 0.03751802071928978, Time: 0s\n",
      "Epoch [2/10], Batch [70/297], Loss: 0.039166901260614395, Time: 0s\n",
      "Epoch [2/10], Batch [80/297], Loss: 0.04087800160050392, Time: 0s\n",
      "Epoch [2/10], Batch [90/297], Loss: 0.03906362131237984, Time: 0s\n",
      "Epoch [2/10], Batch [100/297], Loss: 0.04396703839302063, Time: 0s\n",
      "Epoch [2/10], Batch [110/297], Loss: 0.03439227491617203, Time: 0s\n",
      "Epoch [2/10], Batch [120/297], Loss: 0.03510551154613495, Time: 0s\n",
      "Epoch [2/10], Batch [130/297], Loss: 0.035675741732120514, Time: 0s\n",
      "Epoch [2/10], Batch [140/297], Loss: 0.03511568531394005, Time: 0s\n",
      "Epoch [2/10], Batch [150/297], Loss: 0.04818272218108177, Time: 0s\n",
      "Epoch [2/10], Batch [160/297], Loss: 0.038700003176927567, Time: 0s\n",
      "Epoch [2/10], Batch [170/297], Loss: 0.06676867604255676, Time: 0s\n",
      "Epoch [2/10], Batch [180/297], Loss: 0.040804263204336166, Time: 0s\n",
      "Epoch [2/10], Batch [190/297], Loss: 0.04065997898578644, Time: 0s\n",
      "Epoch [2/10], Batch [200/297], Loss: 0.0437622033059597, Time: 0s\n",
      "Epoch [2/10], Batch [210/297], Loss: 0.03557667136192322, Time: 0s\n",
      "Epoch [2/10], Batch [220/297], Loss: 0.035116199404001236, Time: 0s\n",
      "Epoch [2/10], Batch [230/297], Loss: 0.03880096599459648, Time: 0s\n",
      "Epoch [2/10], Batch [240/297], Loss: 0.04558759555220604, Time: 0s\n",
      "Epoch [2/10], Batch [250/297], Loss: 0.03343842178583145, Time: 0s\n",
      "Epoch [2/10], Batch [260/297], Loss: 0.03297419100999832, Time: 0s\n",
      "Epoch [2/10], Batch [270/297], Loss: 0.0866100937128067, Time: 0s\n",
      "Epoch [2/10], Batch [280/297], Loss: 0.0343581885099411, Time: 0s\n",
      "Epoch [2/10], Batch [290/297], Loss: 0.03773253783583641, Time: 0s\n",
      "Epoch [3/10], Batch [10/297], Loss: 0.05836215242743492, Time: 1s\n",
      "Epoch [3/10], Batch [20/297], Loss: 0.04609844088554382, Time: 0s\n",
      "Epoch [3/10], Batch [30/297], Loss: 0.03665553405880928, Time: 0s\n",
      "Epoch [3/10], Batch [40/297], Loss: 0.04406139999628067, Time: 0s\n",
      "Epoch [3/10], Batch [50/297], Loss: 0.07178482413291931, Time: 0s\n",
      "Epoch [3/10], Batch [60/297], Loss: 0.03548122197389603, Time: 0s\n",
      "Epoch [3/10], Batch [70/297], Loss: 0.033356063067913055, Time: 0s\n",
      "Epoch [3/10], Batch [80/297], Loss: 0.03295942023396492, Time: 0s\n",
      "Epoch [3/10], Batch [90/297], Loss: 0.03235761821269989, Time: 0s\n",
      "Epoch [3/10], Batch [100/297], Loss: 0.03182567283511162, Time: 0s\n",
      "Epoch [3/10], Batch [110/297], Loss: 0.030147194862365723, Time: 0s\n",
      "Epoch [3/10], Batch [120/297], Loss: 0.03777136281132698, Time: 0s\n",
      "Epoch [3/10], Batch [130/297], Loss: 0.03868023306131363, Time: 0s\n",
      "Epoch [3/10], Batch [140/297], Loss: 0.0294466745108366, Time: 0s\n",
      "Epoch [3/10], Batch [150/297], Loss: 0.031111735850572586, Time: 0s\n",
      "Epoch [3/10], Batch [160/297], Loss: 0.055703505873680115, Time: 0s\n",
      "Epoch [3/10], Batch [170/297], Loss: 0.04490668699145317, Time: 0s\n",
      "Epoch [3/10], Batch [180/297], Loss: 0.04015742614865303, Time: 0s\n",
      "Epoch [3/10], Batch [190/297], Loss: 0.037359822541475296, Time: 0s\n",
      "Epoch [3/10], Batch [200/297], Loss: 0.03378702327609062, Time: 0s\n",
      "Epoch [3/10], Batch [210/297], Loss: 0.03209555149078369, Time: 0s\n",
      "Epoch [3/10], Batch [220/297], Loss: 0.02876131609082222, Time: 0s\n",
      "Epoch [3/10], Batch [230/297], Loss: 0.03230168670415878, Time: 0s\n",
      "Epoch [3/10], Batch [240/297], Loss: 0.030855242162942886, Time: 0s\n",
      "Epoch [3/10], Batch [250/297], Loss: 0.04542456194758415, Time: 0s\n",
      "Epoch [3/10], Batch [260/297], Loss: 0.03309698402881622, Time: 0s\n",
      "Epoch [3/10], Batch [270/297], Loss: 0.030325589701533318, Time: 0s\n",
      "Epoch [3/10], Batch [280/297], Loss: 0.029691489413380623, Time: 0s\n",
      "Epoch [3/10], Batch [290/297], Loss: 0.028836656361818314, Time: 0s\n",
      "Epoch [4/10], Batch [10/297], Loss: 0.03574958071112633, Time: 1s\n",
      "Epoch [4/10], Batch [20/297], Loss: 0.032724034041166306, Time: 0s\n",
      "Epoch [4/10], Batch [30/297], Loss: 0.0351400226354599, Time: 0s\n",
      "Epoch [4/10], Batch [40/297], Loss: 0.026681136339902878, Time: 0s\n",
      "Epoch [4/10], Batch [50/297], Loss: 0.030128374695777893, Time: 0s\n",
      "Epoch [4/10], Batch [60/297], Loss: 0.0327448695898056, Time: 0s\n",
      "Epoch [4/10], Batch [70/297], Loss: 0.035768553614616394, Time: 0s\n",
      "Epoch [4/10], Batch [80/297], Loss: 0.04091835767030716, Time: 0s\n",
      "Epoch [4/10], Batch [90/297], Loss: 0.031501054763793945, Time: 0s\n",
      "Epoch [4/10], Batch [100/297], Loss: 0.032423291355371475, Time: 0s\n",
      "Epoch [4/10], Batch [110/297], Loss: 0.05290542542934418, Time: 0s\n",
      "Epoch [4/10], Batch [120/297], Loss: 0.02832726575434208, Time: 0s\n",
      "Epoch [4/10], Batch [130/297], Loss: 0.03007650375366211, Time: 0s\n",
      "Epoch [4/10], Batch [140/297], Loss: 0.05556563287973404, Time: 0s\n",
      "Epoch [4/10], Batch [150/297], Loss: 0.03269738331437111, Time: 0s\n",
      "Epoch [4/10], Batch [160/297], Loss: 0.03363562002778053, Time: 0s\n",
      "Epoch [4/10], Batch [170/297], Loss: 0.04978584870696068, Time: 0s\n",
      "Epoch [4/10], Batch [180/297], Loss: 0.0394684337079525, Time: 0s\n",
      "Epoch [4/10], Batch [190/297], Loss: 0.03987058997154236, Time: 0s\n",
      "Epoch [4/10], Batch [200/297], Loss: 0.03208889812231064, Time: 0s\n",
      "Epoch [4/10], Batch [210/297], Loss: 0.03058384545147419, Time: 0s\n",
      "Epoch [4/10], Batch [220/297], Loss: 0.03151047229766846, Time: 0s\n",
      "Epoch [4/10], Batch [230/297], Loss: 0.03742224723100662, Time: 0s\n",
      "Epoch [4/10], Batch [240/297], Loss: 0.029946522787213326, Time: 0s\n",
      "Epoch [4/10], Batch [250/297], Loss: 0.030314557254314423, Time: 0s\n",
      "Epoch [4/10], Batch [260/297], Loss: 0.02930559776723385, Time: 0s\n",
      "Epoch [4/10], Batch [270/297], Loss: 0.03014841116964817, Time: 0s\n",
      "Epoch [4/10], Batch [280/297], Loss: 0.03209243714809418, Time: 0s\n",
      "Epoch [4/10], Batch [290/297], Loss: 0.030912009999155998, Time: 0s\n",
      "Epoch [5/10], Batch [10/297], Loss: 0.04251547157764435, Time: 1s\n",
      "Epoch [5/10], Batch [20/297], Loss: 0.03972204029560089, Time: 0s\n",
      "Epoch [5/10], Batch [30/297], Loss: 0.03222279250621796, Time: 0s\n",
      "Epoch [5/10], Batch [40/297], Loss: 0.028493979945778847, Time: 0s\n",
      "Epoch [5/10], Batch [50/297], Loss: 0.04396277666091919, Time: 0s\n",
      "Epoch [5/10], Batch [60/297], Loss: 0.03973362222313881, Time: 0s\n",
      "Epoch [5/10], Batch [70/297], Loss: 0.035444922745227814, Time: 0s\n",
      "Epoch [5/10], Batch [80/297], Loss: 0.028869152069091797, Time: 0s\n",
      "Epoch [5/10], Batch [90/297], Loss: 0.04471852630376816, Time: 0s\n",
      "Epoch [5/10], Batch [100/297], Loss: 0.029805608093738556, Time: 0s\n",
      "Epoch [5/10], Batch [110/297], Loss: 0.029826344922184944, Time: 0s\n",
      "Epoch [5/10], Batch [120/297], Loss: 0.03196166455745697, Time: 0s\n",
      "Epoch [5/10], Batch [130/297], Loss: 0.03142308443784714, Time: 0s\n",
      "Epoch [5/10], Batch [140/297], Loss: 0.02863280661404133, Time: 0s\n",
      "Epoch [5/10], Batch [150/297], Loss: 0.04748723655939102, Time: 0s\n",
      "Epoch [5/10], Batch [160/297], Loss: 0.031564708799123764, Time: 0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/10], Batch [170/297], Loss: 0.037134215235710144, Time: 0s\n",
      "Epoch [5/10], Batch [180/297], Loss: 0.03536238148808479, Time: 0s\n",
      "Epoch [5/10], Batch [190/297], Loss: 0.02625701017677784, Time: 0s\n",
      "Epoch [5/10], Batch [200/297], Loss: 0.032337773591279984, Time: 0s\n",
      "Epoch [5/10], Batch [210/297], Loss: 0.038995981216430664, Time: 0s\n",
      "Epoch [5/10], Batch [220/297], Loss: 0.031844377517700195, Time: 0s\n",
      "Epoch [5/10], Batch [230/297], Loss: 0.04245379939675331, Time: 0s\n",
      "Epoch [5/10], Batch [240/297], Loss: 0.039061713963747025, Time: 0s\n",
      "Epoch [5/10], Batch [250/297], Loss: 0.029483569785952568, Time: 0s\n",
      "Epoch [5/10], Batch [260/297], Loss: 0.026435939595103264, Time: 0s\n",
      "Epoch [5/10], Batch [270/297], Loss: 0.03345818445086479, Time: 0s\n",
      "Epoch [5/10], Batch [280/297], Loss: 0.037202708423137665, Time: 0s\n",
      "Epoch [5/10], Batch [290/297], Loss: 0.03468162566423416, Time: 0s\n",
      "Epoch [6/10], Batch [10/297], Loss: 0.03425326570868492, Time: 1s\n",
      "Epoch [6/10], Batch [20/297], Loss: 0.03674475848674774, Time: 0s\n",
      "Epoch [6/10], Batch [30/297], Loss: 0.037128180265426636, Time: 0s\n",
      "Epoch [6/10], Batch [40/297], Loss: 0.03090151958167553, Time: 0s\n",
      "Epoch [6/10], Batch [50/297], Loss: 0.033330921083688736, Time: 0s\n",
      "Epoch [6/10], Batch [60/297], Loss: 0.038484103977680206, Time: 0s\n",
      "Epoch [6/10], Batch [70/297], Loss: 0.03085145354270935, Time: 0s\n",
      "Epoch [6/10], Batch [80/297], Loss: 0.031434204429388046, Time: 0s\n",
      "Epoch [6/10], Batch [90/297], Loss: 0.02772178128361702, Time: 0s\n",
      "Epoch [6/10], Batch [100/297], Loss: 0.03365127742290497, Time: 0s\n",
      "Epoch [6/10], Batch [110/297], Loss: 0.031221190467476845, Time: 0s\n",
      "Epoch [6/10], Batch [120/297], Loss: 0.0334353931248188, Time: 0s\n",
      "Epoch [6/10], Batch [130/297], Loss: 0.02870258316397667, Time: 0s\n",
      "Epoch [6/10], Batch [140/297], Loss: 0.028416229411959648, Time: 0s\n",
      "Epoch [6/10], Batch [150/297], Loss: 0.033364515751600266, Time: 0s\n",
      "Epoch [6/10], Batch [160/297], Loss: 0.033375706523656845, Time: 0s\n",
      "Epoch [6/10], Batch [170/297], Loss: 0.03172456473112106, Time: 0s\n",
      "Epoch [6/10], Batch [180/297], Loss: 0.03179344907402992, Time: 0s\n",
      "Epoch [6/10], Batch [190/297], Loss: 0.04113436117768288, Time: 0s\n",
      "Epoch [6/10], Batch [200/297], Loss: 0.032282184809446335, Time: 0s\n",
      "Epoch [6/10], Batch [210/297], Loss: 0.03697898983955383, Time: 0s\n",
      "Epoch [6/10], Batch [220/297], Loss: 0.030468223616480827, Time: 0s\n",
      "Epoch [6/10], Batch [230/297], Loss: 0.03299318999052048, Time: 0s\n",
      "Epoch [6/10], Batch [240/297], Loss: 0.050514042377471924, Time: 0s\n",
      "Epoch [6/10], Batch [250/297], Loss: 0.03598926588892937, Time: 0s\n",
      "Epoch [6/10], Batch [260/297], Loss: 0.03116932511329651, Time: 0s\n",
      "Epoch [6/10], Batch [270/297], Loss: 0.032151371240615845, Time: 0s\n",
      "Epoch [6/10], Batch [280/297], Loss: 0.029771747067570686, Time: 0s\n",
      "Epoch [6/10], Batch [290/297], Loss: 0.03735505789518356, Time: 0s\n",
      "Epoch [7/10], Batch [10/297], Loss: 0.05611347034573555, Time: 1s\n",
      "Epoch [7/10], Batch [20/297], Loss: 0.031218139454722404, Time: 0s\n",
      "Epoch [7/10], Batch [30/297], Loss: 0.030917521566152573, Time: 0s\n",
      "Epoch [7/10], Batch [40/297], Loss: 0.033180151134729385, Time: 0s\n",
      "Epoch [7/10], Batch [50/297], Loss: 0.02603014186024666, Time: 0s\n",
      "Epoch [7/10], Batch [60/297], Loss: 0.027055557817220688, Time: 0s\n",
      "Epoch [7/10], Batch [70/297], Loss: 0.03219863399863243, Time: 0s\n",
      "Epoch [7/10], Batch [80/297], Loss: 0.027395308017730713, Time: 0s\n",
      "Epoch [7/10], Batch [90/297], Loss: 0.03389614447951317, Time: 0s\n",
      "Epoch [7/10], Batch [100/297], Loss: 0.028776269406080246, Time: 0s\n",
      "Epoch [7/10], Batch [110/297], Loss: 0.037723325192928314, Time: 0s\n",
      "Epoch [7/10], Batch [120/297], Loss: 0.02919660322368145, Time: 0s\n",
      "Epoch [7/10], Batch [130/297], Loss: 0.037346936762332916, Time: 0s\n",
      "Epoch [7/10], Batch [140/297], Loss: 0.03414356708526611, Time: 0s\n",
      "Epoch [7/10], Batch [150/297], Loss: 0.029085567221045494, Time: 0s\n",
      "Epoch [7/10], Batch [160/297], Loss: 0.04845185577869415, Time: 0s\n",
      "Epoch [7/10], Batch [170/297], Loss: 0.027682382613420486, Time: 0s\n",
      "Epoch [7/10], Batch [180/297], Loss: 0.032004762440919876, Time: 0s\n",
      "Epoch [7/10], Batch [190/297], Loss: 0.027206286787986755, Time: 0s\n",
      "Epoch [7/10], Batch [200/297], Loss: 0.052145589143037796, Time: 0s\n",
      "Epoch [7/10], Batch [210/297], Loss: 0.03180558234453201, Time: 0s\n",
      "Epoch [7/10], Batch [220/297], Loss: 0.05244895815849304, Time: 0s\n",
      "Epoch [7/10], Batch [230/297], Loss: 0.026979591697454453, Time: 0s\n",
      "Epoch [7/10], Batch [240/297], Loss: 0.028025774285197258, Time: 0s\n",
      "Epoch [7/10], Batch [250/297], Loss: 0.03321449086070061, Time: 0s\n",
      "Epoch [7/10], Batch [260/297], Loss: 0.051260899752378464, Time: 0s\n",
      "Epoch [7/10], Batch [270/297], Loss: 0.026854651048779488, Time: 0s\n",
      "Epoch [7/10], Batch [280/297], Loss: 0.03171679005026817, Time: 0s\n",
      "Epoch [7/10], Batch [290/297], Loss: 0.03510670363903046, Time: 0s\n",
      "Epoch [8/10], Batch [10/297], Loss: 0.03276791796088219, Time: 1s\n",
      "Epoch [8/10], Batch [20/297], Loss: 0.0387905016541481, Time: 0s\n",
      "Epoch [8/10], Batch [30/297], Loss: 0.027225177735090256, Time: 0s\n",
      "Epoch [8/10], Batch [40/297], Loss: 0.04216066747903824, Time: 0s\n",
      "Epoch [8/10], Batch [50/297], Loss: 0.02890823967754841, Time: 0s\n",
      "Epoch [8/10], Batch [60/297], Loss: 0.031161732971668243, Time: 0s\n",
      "Epoch [8/10], Batch [70/297], Loss: 0.035731736570596695, Time: 0s\n",
      "Epoch [8/10], Batch [80/297], Loss: 0.03184489533305168, Time: 0s\n",
      "Epoch [8/10], Batch [90/297], Loss: 0.03948220610618591, Time: 0s\n",
      "Epoch [8/10], Batch [100/297], Loss: 0.029818641021847725, Time: 0s\n",
      "Epoch [8/10], Batch [110/297], Loss: 0.03677111119031906, Time: 0s\n",
      "Epoch [8/10], Batch [120/297], Loss: 0.02614097110927105, Time: 0s\n",
      "Epoch [8/10], Batch [130/297], Loss: 0.0335216261446476, Time: 0s\n",
      "Epoch [8/10], Batch [140/297], Loss: 0.046884290874004364, Time: 0s\n",
      "Epoch [8/10], Batch [150/297], Loss: 0.026051033288240433, Time: 0s\n",
      "Epoch [8/10], Batch [160/297], Loss: 0.03361224755644798, Time: 0s\n",
      "Epoch [8/10], Batch [170/297], Loss: 0.043855585157871246, Time: 0s\n",
      "Epoch [8/10], Batch [180/297], Loss: 0.03253931924700737, Time: 0s\n",
      "Epoch [8/10], Batch [190/297], Loss: 0.03728865459561348, Time: 0s\n",
      "Epoch [8/10], Batch [200/297], Loss: 0.02449622005224228, Time: 0s\n",
      "Epoch [8/10], Batch [210/297], Loss: 0.026603056117892265, Time: 0s\n",
      "Epoch [8/10], Batch [220/297], Loss: 0.03219180554151535, Time: 0s\n",
      "Epoch [8/10], Batch [230/297], Loss: 0.03391994908452034, Time: 0s\n",
      "Epoch [8/10], Batch [240/297], Loss: 0.03139163553714752, Time: 0s\n",
      "Epoch [8/10], Batch [250/297], Loss: 0.027324603870511055, Time: 0s\n",
      "Epoch [8/10], Batch [260/297], Loss: 0.031196115538477898, Time: 0s\n",
      "Epoch [8/10], Batch [270/297], Loss: 0.02947346307337284, Time: 0s\n",
      "Epoch [8/10], Batch [280/297], Loss: 0.039234600961208344, Time: 0s\n",
      "Epoch [8/10], Batch [290/297], Loss: 0.03852161020040512, Time: 0s\n",
      "Epoch [9/10], Batch [10/297], Loss: 0.0347769521176815, Time: 1s\n",
      "Epoch [9/10], Batch [20/297], Loss: 0.026706518605351448, Time: 0s\n",
      "Epoch [9/10], Batch [30/297], Loss: 0.032935917377471924, Time: 0s\n",
      "Epoch [9/10], Batch [40/297], Loss: 0.028970306739211082, Time: 0s\n",
      "Epoch [9/10], Batch [50/297], Loss: 0.03000675141811371, Time: 0s\n",
      "Epoch [9/10], Batch [60/297], Loss: 0.043294262140989304, Time: 0s\n",
      "Epoch [9/10], Batch [70/297], Loss: 0.041473232209682465, Time: 0s\n",
      "Epoch [9/10], Batch [80/297], Loss: 0.05150486156344414, Time: 0s\n",
      "Epoch [9/10], Batch [90/297], Loss: 0.02747988887131214, Time: 0s\n",
      "Epoch [9/10], Batch [100/297], Loss: 0.04096128046512604, Time: 0s\n",
      "Epoch [9/10], Batch [110/297], Loss: 0.0322449617087841, Time: 0s\n",
      "Epoch [9/10], Batch [120/297], Loss: 0.027494119480252266, Time: 0s\n",
      "Epoch [9/10], Batch [130/297], Loss: 0.02727230079472065, Time: 0s\n",
      "Epoch [9/10], Batch [140/297], Loss: 0.030061744153499603, Time: 0s\n",
      "Epoch [9/10], Batch [150/297], Loss: 0.031864941120147705, Time: 0s\n",
      "Epoch [9/10], Batch [160/297], Loss: 0.04772114381194115, Time: 0s\n",
      "Epoch [9/10], Batch [170/297], Loss: 0.04350007325410843, Time: 0s\n",
      "Epoch [9/10], Batch [180/297], Loss: 0.03782038763165474, Time: 0s\n",
      "Epoch [9/10], Batch [190/297], Loss: 0.03274210914969444, Time: 0s\n",
      "Epoch [9/10], Batch [200/297], Loss: 0.027051854878664017, Time: 0s\n",
      "Epoch [9/10], Batch [210/297], Loss: 0.03172667697072029, Time: 0s\n",
      "Epoch [9/10], Batch [220/297], Loss: 0.027202382683753967, Time: 0s\n",
      "Epoch [9/10], Batch [230/297], Loss: 0.028839334845542908, Time: 0s\n",
      "Epoch [9/10], Batch [240/297], Loss: 0.029531650245189667, Time: 0s\n",
      "Epoch [9/10], Batch [250/297], Loss: 0.027982087805867195, Time: 0s\n",
      "Epoch [9/10], Batch [260/297], Loss: 0.026484806090593338, Time: 0s\n",
      "Epoch [9/10], Batch [270/297], Loss: 0.027431221678853035, Time: 0s\n",
      "Epoch [9/10], Batch [280/297], Loss: 0.04173126816749573, Time: 0s\n",
      "Epoch [9/10], Batch [290/297], Loss: 0.026426246389746666, Time: 0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10], Batch [10/297], Loss: 0.029420094564557076, Time: 1s\n",
      "Epoch [10/10], Batch [20/297], Loss: 0.02880764752626419, Time: 0s\n",
      "Epoch [10/10], Batch [30/297], Loss: 0.02982618659734726, Time: 0s\n",
      "Epoch [10/10], Batch [40/297], Loss: 0.03563801199197769, Time: 0s\n",
      "Epoch [10/10], Batch [50/297], Loss: 0.03392162546515465, Time: 0s\n",
      "Epoch [10/10], Batch [60/297], Loss: 0.026278866454958916, Time: 0s\n",
      "Epoch [10/10], Batch [70/297], Loss: 0.029527824372053146, Time: 0s\n",
      "Epoch [10/10], Batch [80/297], Loss: 0.031557485461235046, Time: 0s\n",
      "Epoch [10/10], Batch [90/297], Loss: 0.02765764854848385, Time: 0s\n",
      "Epoch [10/10], Batch [100/297], Loss: 0.03136088326573372, Time: 0s\n",
      "Epoch [10/10], Batch [110/297], Loss: 0.03074968047440052, Time: 0s\n",
      "Epoch [10/10], Batch [120/297], Loss: 0.03424854949116707, Time: 0s\n",
      "Epoch [10/10], Batch [130/297], Loss: 0.023816155269742012, Time: 0s\n",
      "Epoch [10/10], Batch [140/297], Loss: 0.036441683769226074, Time: 0s\n",
      "Epoch [10/10], Batch [150/297], Loss: 0.02812570333480835, Time: 0s\n",
      "Epoch [10/10], Batch [160/297], Loss: 0.025858230888843536, Time: 0s\n",
      "Epoch [10/10], Batch [170/297], Loss: 0.047976456582546234, Time: 0s\n",
      "Epoch [10/10], Batch [180/297], Loss: 0.027500083670020103, Time: 0s\n",
      "Epoch [10/10], Batch [190/297], Loss: 0.029253996908664703, Time: 0s\n",
      "Epoch [10/10], Batch [200/297], Loss: 0.03250672295689583, Time: 0s\n",
      "Epoch [10/10], Batch [210/297], Loss: 0.026494834572076797, Time: 0s\n",
      "Epoch [10/10], Batch [220/297], Loss: 0.029073722660541534, Time: 0s\n",
      "Epoch [10/10], Batch [230/297], Loss: 0.022537555545568466, Time: 0s\n",
      "Epoch [10/10], Batch [240/297], Loss: 0.030289968475699425, Time: 0s\n",
      "Epoch [10/10], Batch [250/297], Loss: 0.03547501564025879, Time: 0s\n",
      "Epoch [10/10], Batch [260/297], Loss: 0.026177652180194855, Time: 0s\n",
      "Epoch [10/10], Batch [270/297], Loss: 0.028115106746554375, Time: 0s\n",
      "Epoch [10/10], Batch [280/297], Loss: 0.0283285491168499, Time: 0s\n",
      "Epoch [10/10], Batch [290/297], Loss: 0.04257120192050934, Time: 0s\n",
      "Final loss: 0.013670100830495358\n",
      "Wall time: 12.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import train\n",
    "\n",
    "device='cpu'\n",
    "\n",
    "model = train.train_model(train_df, train_idx_map, batchSize=200,\n",
    "                          print_itr=10, numEpochs=10, model_cols=model_cols,\n",
    "                          learningRate=0.0001, device=device, num_workers=5,\n",
    "                          loss='L2', hiddenSize=300)\n",
    "\n",
    "y_pred = train.predict(model, X_test, device=device) # get predictions for each train\n",
    "y_pred_df = pd.DataFrame(y_pred, columns=test_df.columns[:-2])  # put results into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Test set MAE (L1) loss: 0.09666776418831212\n",
      "    Test set MSE (L2) loss: 0.05394306212580342\n"
     ]
    }
   ],
   "source": [
    "print(f'    Test set MAE (L1) loss: {mean_absolute_error(y_test, y_pred_df)}')\n",
    "print(f'    Test set MSE (L2) loss: {mean_squared_error(y_test, y_pred_df)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss Tracking\n",
    "\n",
    "|Test L1 Loss | Test L2 Loss | NN Change History | Time |\n",
    "|:-|:-|:-|-|\n",
    "|0.2905|0.2089|norads=10%, epochs=10, batchSize=200,<br> learn=0.0001, device=cpu, loss=l2,<br> num_workers=5, hidden=10| 8s|\n",
    "|0.1501|0.0651|norads=50%| 11s|\n",
    "|0.1257|0.0543|norads=100%| 13s|\n",
    "|0.1392|0.0620|norads=10%, hidden=100| 9s|\n",
    "|0.0999|0.0557|norads=50%| 12s|\n",
    "|0.0944|0.0518|norads=100%| 15s|\n",
    "|0.1162|0.0587|norads=10%, hidden=300| 9s|\n",
    "|0.0967|0.0544|norads=50%| 12s|\n",
    "|0.0932|0.0511|norads=100%| 15s|\n",
    "|0.0931|0.0560|norads=10%, loss=l1| 9s|\n",
    "|0.0816|0.0649|norads=50%| 12s|\n",
    "|0.0803|0.0635|norads=100%| 15s|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BSTAR</th>\n",
       "      <th>INCLINATION</th>\n",
       "      <th>RA_OF_ASC_NODE</th>\n",
       "      <th>ECCENTRICITY</th>\n",
       "      <th>ARG_OF_PERICENTER</th>\n",
       "      <th>MEAN_ANOMALY</th>\n",
       "      <th>MEAN_MOTION</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000198</td>\n",
       "      <td>99.2262</td>\n",
       "      <td>99.0297</td>\n",
       "      <td>0.006856</td>\n",
       "      <td>181.2493</td>\n",
       "      <td>178.8503</td>\n",
       "      <td>13.885952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000169</td>\n",
       "      <td>99.2266</td>\n",
       "      <td>99.5291</td>\n",
       "      <td>0.006851</td>\n",
       "      <td>179.9495</td>\n",
       "      <td>180.1667</td>\n",
       "      <td>13.885950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000241</td>\n",
       "      <td>99.2237</td>\n",
       "      <td>88.1223</td>\n",
       "      <td>0.006796</td>\n",
       "      <td>211.1098</td>\n",
       "      <td>148.6028</td>\n",
       "      <td>13.885913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000214</td>\n",
       "      <td>99.2263</td>\n",
       "      <td>98.0320</td>\n",
       "      <td>0.006846</td>\n",
       "      <td>183.9584</td>\n",
       "      <td>176.1041</td>\n",
       "      <td>13.885948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000268</td>\n",
       "      <td>99.2242</td>\n",
       "      <td>79.1433</td>\n",
       "      <td>0.006793</td>\n",
       "      <td>235.6724</td>\n",
       "      <td>123.8004</td>\n",
       "      <td>13.885863</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      BSTAR  INCLINATION  RA_OF_ASC_NODE  ECCENTRICITY  ARG_OF_PERICENTER  \\\n",
       "0  0.000198      99.2262         99.0297      0.006856           181.2493   \n",
       "1  0.000169      99.2266         99.5291      0.006851           179.9495   \n",
       "2  0.000241      99.2237         88.1223      0.006796           211.1098   \n",
       "3  0.000214      99.2263         98.0320      0.006846           183.9584   \n",
       "4  0.000268      99.2242         79.1433      0.006793           235.6724   \n",
       "\n",
       "   MEAN_ANOMALY  MEAN_MOTION  \n",
       "0      178.8503    13.885952  \n",
       "1      180.1667    13.885950  \n",
       "2      148.6028    13.885913  \n",
       "3      176.1041    13.885948  \n",
       "4      123.8004    13.885863  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_data.normalize_all_columns(y_test.head().copy(), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BSTAR</th>\n",
       "      <th>INCLINATION</th>\n",
       "      <th>RA_OF_ASC_NODE</th>\n",
       "      <th>ECCENTRICITY</th>\n",
       "      <th>ARG_OF_PERICENTER</th>\n",
       "      <th>MEAN_ANOMALY</th>\n",
       "      <th>MEAN_MOTION</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000615</td>\n",
       "      <td>99.404831</td>\n",
       "      <td>140.879852</td>\n",
       "      <td>0.006192</td>\n",
       "      <td>187.490829</td>\n",
       "      <td>172.788605</td>\n",
       "      <td>13.920848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000006</td>\n",
       "      <td>97.879700</td>\n",
       "      <td>134.398941</td>\n",
       "      <td>0.006359</td>\n",
       "      <td>180.949326</td>\n",
       "      <td>175.144318</td>\n",
       "      <td>13.961693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000737</td>\n",
       "      <td>98.088058</td>\n",
       "      <td>150.278137</td>\n",
       "      <td>0.005778</td>\n",
       "      <td>179.294693</td>\n",
       "      <td>181.378052</td>\n",
       "      <td>13.919862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000616</td>\n",
       "      <td>99.335999</td>\n",
       "      <td>136.496399</td>\n",
       "      <td>0.006369</td>\n",
       "      <td>198.032944</td>\n",
       "      <td>163.733322</td>\n",
       "      <td>13.918449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000383</td>\n",
       "      <td>99.145355</td>\n",
       "      <td>140.204926</td>\n",
       "      <td>0.006108</td>\n",
       "      <td>182.397659</td>\n",
       "      <td>175.754379</td>\n",
       "      <td>13.938741</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      BSTAR  INCLINATION  RA_OF_ASC_NODE  ECCENTRICITY  ARG_OF_PERICENTER  \\\n",
       "0  0.000615    99.404831      140.879852      0.006192         187.490829   \n",
       "1  0.000006    97.879700      134.398941      0.006359         180.949326   \n",
       "2  0.000737    98.088058      150.278137      0.005778         179.294693   \n",
       "3  0.000616    99.335999      136.496399      0.006369         198.032944   \n",
       "4  0.000383    99.145355      140.204926      0.006108         182.397659   \n",
       "\n",
       "   MEAN_ANOMALY  MEAN_MOTION  \n",
       "0    172.788605    13.920848  \n",
       "1    175.144318    13.961693  \n",
       "2    181.378052    13.919862  \n",
       "3    163.733322    13.918449  \n",
       "4    175.754379    13.938741  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_data.normalize_all_columns(y_pred_df.head().copy(), reverse=True)  # reverse the normalization"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
