{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Raw Data into Train/Val/Test sets and Save\n",
    "This also has the ability to write the raw data files into train/validate/test files.  These files only contain the raw TLE data.  Extra pre-processing is still required as well as the assembly of input/label data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from load_data import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading files from path: C:\\Datasets\\gp_history\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1472/1472 [03:34<00:00,  6.85it/s]\n",
      "  0%|                                                                                            | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished loading.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:08<00:00,  2.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished assembling.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "norad_lists = load_norads(['train','validate','secret_test'])\n",
    "df_dict = load_data(norad_lists, use_all_data=True, debug=True, multiproc=True)  # Takes about 4min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving files to path: C:\\Datasets\\gp_history/raw_compiled\n",
      "Writing raw data for to: C:\\Datasets\\gp_history/raw_compiled/train.pkl\n",
      "Writing raw data for to: C:\\Datasets\\gp_history/raw_compiled/test.pklWriting raw data for to: C:\\Datasets\\gp_history/raw_compiled/secret_test.pkl\n",
      "\n",
      "Finished saving C:\\Datasets\\gp_history/raw_compiled/secret_test.pkl\n",
      "Finished saving C:\\Datasets\\gp_history/raw_compiled/test.pkl\n",
      "Finished saving C:\\Datasets\\gp_history/raw_compiled/train.pkl\n"
     ]
    }
   ],
   "source": [
    "write_data(df_dict, use_all_data=True, debug=True, threaded=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Raw Train set and create a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 18.4 s\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "files = ['train']\n",
    "\n",
    "%time df = pd.read_pickle(os.environ['GP_HIST_PATH'] + '/raw_compiled/train.pkl' )  # Takes about 20s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4min 2s\n"
     ]
    }
   ],
   "source": [
    "import clean_data\n",
    "\n",
    "%time df = clean_data.add_epoch_data(df)  # Takes about 4min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def create_index_map(df):\n",
    "    '''\n",
    "    This will create a map between an input record (for X_train) and\n",
    "    a label record (for y_train) that will be used by the pytorch\n",
    "    dataset class to dynamically build a dataset without taking up\n",
    "    more space than is necessary.\n",
    "    '''\n",
    "    \n",
    "    # ML Structure\n",
    "    # Input:\n",
    "    #  - Reference TLE Data (+ EPOCH)\n",
    "    #  - Target EPOCH\n",
    "    # Output:\n",
    "    #  - Target TLE Data\n",
    "    \n",
    "    def groups(lst):\n",
    "        arr = lst.copy()\n",
    "        np.random.shuffle(arr)\n",
    "        i=1\n",
    "        if len(lst)<=1:\n",
    "            return\n",
    "        while True:\n",
    "            if i==len(lst):\n",
    "                yield tuple((arr[i-1],arr[0]))\n",
    "                break\n",
    "            else:\n",
    "                yield tuple((arr[i-1],arr[i]))\n",
    "                i+=1\n",
    "    \n",
    "    # For each unique NORAD, find all TLE indexes and generate\n",
    "    # a list of combinations\n",
    "    idx_pairs = []\n",
    "    for norad in df['NORAD_CAT_ID'].unique():\n",
    "        norad_idxs = df[df['NORAD_CAT_ID']==norad].index.values\n",
    "        if len(norad_idxs > 1):\n",
    "            idx_pairs.extend(groups(norad_idxs))\n",
    "    idx_pairs = np.array(idx_pairs)\n",
    "    \n",
    "#     # Build our X/Y datasets\n",
    "#     X_all = df.loc[idx_pairs[:,0]].reset_index()\n",
    "#     Y_all = df.loc[idx_pairs[:,1]].reset_index()\n",
    "    \n",
    "#     # This will be the column that links x and y\n",
    "#     key_columns = ['epoch_jd', 'epoch_fr']\n",
    "#     target_columns = ['target_epoch_jd', 'target_epoch_fr']\n",
    "#     X_all[target_columns] = Y_all[key_columns]\n",
    "    \n",
    "    return idx_pairs\n",
    "\n",
    "%time idx_pairs = create_index_map(df)  # 16min - look at ways to improve this through parallelism/concurrency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.8010e-05, 0.0000e+00, 2.5919e-03, 6.2242e+01, 1.8016e+02, 7.0489e-02,\n",
       "        2.6568e+02, 8.6277e+01, 1.2853e+01, 2.4531e+06, 5.9639e-01, 2.4531e+06,\n",
       "        6.6644e-01], dtype=torch.float64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tensor([-2.0000e-08,  0.0000e+00,  1.0000e-04,  7.3360e+01,  3.4569e+02,\n",
       "         8.8152e-03,  2.7040e+02,  8.8691e+01,  1.2642e+01],\n",
       "       dtype=torch.float64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test our dataset structure\n",
    "import torch\n",
    "\n",
    "model_cols = ['MEAN_MOTION_DOT', 'MEAN_MOTION_DDOT', 'BSTAR', 'INCLINATION', 'RA_OF_ASC_NODE',\n",
    "              'ECCENTRICITY', 'ARG_OF_PERICENTER', 'MEAN_ANOMALY', 'MEAN_MOTION', 'epoch_jd', 'epoch_fr']\n",
    "\n",
    "t1 = torch.from_numpy(df.to_numpy())  # data\n",
    "p = torch.tensor([[0,1]])\n",
    "\n",
    "index = 0\n",
    "X_pre = t1[p[index][0]]\n",
    "X = torch.cat((X_pre, t1[p[index][1]][-2:]), 0)\n",
    "y = t1[p[index][1]][:-2]\n",
    "display(X)\n",
    "display(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "torch.manual_seed(0)\n",
    "\n",
    "hiddenSize = 300\n",
    "batchSize = 200\n",
    "learningRate = 0.01\n",
    "numEpochs = 10\n",
    "\n",
    "model_cols = ['MEAN_MOTION_DOT', 'MEAN_MOTION_DDOT', 'BSTAR', 'INCLINATION', 'RA_OF_ASC_NODE',\n",
    "              'ECCENTRICITY', 'ARG_OF_PERICENTER', 'MEAN_ANOMALY', 'MEAN_MOTION', 'epoch_jd', 'epoch_fr']\n",
    "\n",
    "#device = torch.device('cpu')\n",
    "device = torch.device('cuda')\n",
    "\n",
    "def to_device(data, device):\n",
    "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
    "    if isinstance(data, (list,tuple)):\n",
    "        return [to_device(x, device) for x in data]\n",
    "    return data.to(device, non_blocking=True)\n",
    "\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "    'Characterizes a dataset for PyTorch'\n",
    "    def __init__(self, data, idx_pairs, device='cpu'):\n",
    "        'Initialization'\n",
    "        self.data = to_device(torch.from_numpy(data.to_numpy()).float(), device)\n",
    "        self.idx_pairs = to_device(torch.from_numpy(idx_pairs).float(), device)\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the total number of samples'\n",
    "        return len(self.idx_pairs)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generates one sample of data'\n",
    "        p = self.idx_pairs[index]\n",
    "        \n",
    "        # This will use the idx_pairs (x,y) to build the inputs(X) and labels (y)\n",
    "        # output.  It adds the last 2 columns of y to X and removes them from y.\n",
    "        X = torch.cat((self.data[p[index][0]], self.data[p[index][1]][-2:]), 0)\n",
    "        y = self.data[p[index][1]][:-2]\n",
    "\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NNModel(nn.Module):\n",
    "    def __init__(self, inputSize, outputSize, hiddenSize, activate=None):\n",
    "        super().__init__()\n",
    "        self.activate = nn.Sigmoid() if activate == \"Sigmoid\" else nn.Tanh() if activate == \"Tanh\" else nn.ReLU()\n",
    "        self.layer1 = nn.Linear(inputSize, hiddenSize)\n",
    "        self.layer2 = nn.Linear(hiddenSize, outputSize)\n",
    "\n",
    "    def forward(self, X):\n",
    "        hidden = self.activate(self.layer1(X))\n",
    "        return self.layer2(hidden)\n",
    "        \n",
    "        \n",
    "net = NNModel(len(model_cols) + 2, len(model_cols) - 2, hiddenSize)\n",
    "to_device(net, device)\n",
    "criterion = nn.L1Loss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=learningRate)\n",
    "\n",
    "trainDataset = Dataset(df[model_cols], idx_pairs, device)\n",
    "trainLoader = torch.utils.data.DataLoader(dataset=trainDataset,\n",
    "                                          batch_size=batchSize,\n",
    "                                          shuffle=True,\n",
    "                                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MEAN_MOTION_DOT</th>\n",
       "      <th>MEAN_MOTION_DDOT</th>\n",
       "      <th>BSTAR</th>\n",
       "      <th>INCLINATION</th>\n",
       "      <th>RA_OF_ASC_NODE</th>\n",
       "      <th>ECCENTRICITY</th>\n",
       "      <th>ARG_OF_PERICENTER</th>\n",
       "      <th>MEAN_ANOMALY</th>\n",
       "      <th>MEAN_MOTION</th>\n",
       "      <th>epoch_jd</th>\n",
       "      <th>epoch_fr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.801000e-05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002592</td>\n",
       "      <td>62.2415</td>\n",
       "      <td>180.1561</td>\n",
       "      <td>0.070489</td>\n",
       "      <td>265.6761</td>\n",
       "      <td>86.2771</td>\n",
       "      <td>12.852684</td>\n",
       "      <td>2453122.5</td>\n",
       "      <td>0.596391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-2.000000e-08</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>73.3600</td>\n",
       "      <td>345.6887</td>\n",
       "      <td>0.008815</td>\n",
       "      <td>270.3999</td>\n",
       "      <td>88.6911</td>\n",
       "      <td>12.642166</td>\n",
       "      <td>2453122.5</td>\n",
       "      <td>0.666444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.280000e-05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001076</td>\n",
       "      <td>83.0239</td>\n",
       "      <td>250.9465</td>\n",
       "      <td>0.008493</td>\n",
       "      <td>184.3222</td>\n",
       "      <td>175.7249</td>\n",
       "      <td>13.856401</td>\n",
       "      <td>2453122.5</td>\n",
       "      <td>0.823075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.320000e-06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000166</td>\n",
       "      <td>70.9841</td>\n",
       "      <td>207.4830</td>\n",
       "      <td>0.020756</td>\n",
       "      <td>161.3777</td>\n",
       "      <td>199.5075</td>\n",
       "      <td>13.715209</td>\n",
       "      <td>2453122.5</td>\n",
       "      <td>0.654993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.280000e-06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000739</td>\n",
       "      <td>90.1460</td>\n",
       "      <td>192.1834</td>\n",
       "      <td>0.002746</td>\n",
       "      <td>300.4617</td>\n",
       "      <td>59.3655</td>\n",
       "      <td>12.992417</td>\n",
       "      <td>2453122.5</td>\n",
       "      <td>0.154908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54899682</th>\n",
       "      <td>1.871000e-05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000263</td>\n",
       "      <td>51.4710</td>\n",
       "      <td>233.3741</td>\n",
       "      <td>0.152907</td>\n",
       "      <td>349.1034</td>\n",
       "      <td>7.9896</td>\n",
       "      <td>12.139866</td>\n",
       "      <td>2459296.5</td>\n",
       "      <td>0.821280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54899683</th>\n",
       "      <td>2.870000e-05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000430</td>\n",
       "      <td>62.8880</td>\n",
       "      <td>161.0401</td>\n",
       "      <td>0.046410</td>\n",
       "      <td>125.6077</td>\n",
       "      <td>238.9153</td>\n",
       "      <td>14.233898</td>\n",
       "      <td>2459297.5</td>\n",
       "      <td>0.189309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54899684</th>\n",
       "      <td>6.427000e-05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003201</td>\n",
       "      <td>51.3447</td>\n",
       "      <td>252.9299</td>\n",
       "      <td>0.083999</td>\n",
       "      <td>62.7382</td>\n",
       "      <td>305.6523</td>\n",
       "      <td>13.083883</td>\n",
       "      <td>2459296.5</td>\n",
       "      <td>0.659999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54899685</th>\n",
       "      <td>7.216000e-05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000945</td>\n",
       "      <td>97.9051</td>\n",
       "      <td>133.8333</td>\n",
       "      <td>0.000740</td>\n",
       "      <td>263.2779</td>\n",
       "      <td>96.7592</td>\n",
       "      <td>14.806388</td>\n",
       "      <td>2459297.5</td>\n",
       "      <td>0.102227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54899686</th>\n",
       "      <td>1.490816e-01</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.003522</td>\n",
       "      <td>49.8848</td>\n",
       "      <td>104.3397</td>\n",
       "      <td>0.000732</td>\n",
       "      <td>311.7372</td>\n",
       "      <td>137.6448</td>\n",
       "      <td>16.287651</td>\n",
       "      <td>2459297.5</td>\n",
       "      <td>0.379570</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>54899687 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          MEAN_MOTION_DOT  MEAN_MOTION_DDOT     BSTAR  INCLINATION  \\\n",
       "0            1.801000e-05          0.000000  0.002592      62.2415   \n",
       "1           -2.000000e-08          0.000000  0.000100      73.3600   \n",
       "2            1.280000e-05          0.000000  0.001076      83.0239   \n",
       "3            1.320000e-06          0.000000  0.000166      70.9841   \n",
       "4            2.280000e-06          0.000000  0.000739      90.1460   \n",
       "...                   ...               ...       ...          ...   \n",
       "54899682     1.871000e-05          0.000000  0.000263      51.4710   \n",
       "54899683     2.870000e-05          0.000000  0.000430      62.8880   \n",
       "54899684     6.427000e-05          0.000000  0.003201      51.3447   \n",
       "54899685     7.216000e-05          0.000000  0.000945      97.9051   \n",
       "54899686     1.490816e-01          0.000012  0.003522      49.8848   \n",
       "\n",
       "          RA_OF_ASC_NODE  ECCENTRICITY  ARG_OF_PERICENTER  MEAN_ANOMALY  \\\n",
       "0               180.1561      0.070489           265.6761       86.2771   \n",
       "1               345.6887      0.008815           270.3999       88.6911   \n",
       "2               250.9465      0.008493           184.3222      175.7249   \n",
       "3               207.4830      0.020756           161.3777      199.5075   \n",
       "4               192.1834      0.002746           300.4617       59.3655   \n",
       "...                  ...           ...                ...           ...   \n",
       "54899682        233.3741      0.152907           349.1034        7.9896   \n",
       "54899683        161.0401      0.046410           125.6077      238.9153   \n",
       "54899684        252.9299      0.083999            62.7382      305.6523   \n",
       "54899685        133.8333      0.000740           263.2779       96.7592   \n",
       "54899686        104.3397      0.000732           311.7372      137.6448   \n",
       "\n",
       "          MEAN_MOTION   epoch_jd  epoch_fr  \n",
       "0           12.852684  2453122.5  0.596391  \n",
       "1           12.642166  2453122.5  0.666444  \n",
       "2           13.856401  2453122.5  0.823075  \n",
       "3           13.715209  2453122.5  0.654993  \n",
       "4           12.992417  2453122.5  0.154908  \n",
       "...               ...        ...       ...  \n",
       "54899682    12.139866  2459296.5  0.821280  \n",
       "54899683    14.233898  2459297.5  0.189309  \n",
       "54899684    13.083883  2459296.5  0.659999  \n",
       "54899685    14.806388  2459297.5  0.102227  \n",
       "54899686    16.287651  2459297.5  0.379570  \n",
       "\n",
       "[54899687 rows x 11 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[model_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Beginning training!\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 50238054 is out of bounds for dimension 0 with size 2",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\cmtle\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    515\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    516\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 517\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    518\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    519\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\cmtle\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    555\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    556\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 557\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    558\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    559\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\cmtle\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\cmtle\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-62-db4c948bea72>\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m     34\u001b[0m         \u001b[1;31m# This will use the idx_pairs (x,y) to build the inputs(X) and labels (y)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[1;31m# output.  It adds the last 2 columns of y to X and removes them from y.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 50238054 is out of bounds for dimension 0 with size 2"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print('>>> Beginning training!')\n",
    "for epoch in range(numEpochs):\n",
    "    for i, (inputs, labels) in enumerate(trainLoader):\n",
    "        optimizer.zero_grad()\n",
    "        # Forward propagation\n",
    "        outputs = net(inputs)\n",
    "        # Backpropagation\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        # Gradient descent\n",
    "        optimizer.step()\n",
    "        # Logging\n",
    "        if (i+1) % 1000 == 0:\n",
    "            print('Epoch [{}/{}], Step [{}/{}], Loss: {}'.format(epoch+1, numEpochs, i+1,\n",
    "                                                                 len(trainDataset)//batchSize, loss))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
